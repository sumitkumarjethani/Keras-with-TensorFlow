{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdd3d07",
   "metadata": {},
   "source": [
    "In this episode, we'll demonstrate how to process numerical data that we'll later use to train our very first artificial neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d813128",
   "metadata": {},
   "source": [
    "## Samples and Labels\n",
    "\n",
    "To train any neural network in a supervised learning task, we first need a data set of samples and the corresponding labels for those samples.\n",
    "\n",
    "When referring to samples, we're just referring to the underlying data set, where each individual item or data point within that set is called a sample. Labels are the corresponding labels for the samples.\n",
    "\n",
    "**Note that in deep learning, samples are also commonly referred to as input data or inputs, and labels are also commonly referred to as target data or targets.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf7ce9e",
   "metadata": {},
   "source": [
    "###  Expected data format\n",
    "\n",
    "When preparing data, we first need to understand the format that the data need to be in for the end goal we have in mind. In our case, we want our data to be in a format that we can pass to a neural network model.\n",
    "\n",
    "The first model we'll build in an upcoming episode will be a **Sequential model** from the Keras API integrated within TensorFlow.\n",
    "\n",
    "The Sequential model receives data during training, which occurs when we call the ***fit()*** function on the model.\n",
    "\n",
    "[Documentation of fit() function](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit)\n",
    "\n",
    "In the ***fit()*** function: **x** is the input data and **y** are the labels for that input data in the same format or data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab697b1a",
   "metadata": {},
   "source": [
    "## Process data in code\n",
    "\n",
    "We'll start out with a very simple classification task using a simple numerical data set.\n",
    "\n",
    "We first need to import the libraries we'll be working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4057065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import randint\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e02e5",
   "metadata": {},
   "source": [
    "Next, we create two empty lists. One will hold the **input data**, the other will hold the **target data or labels**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b4ecf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = []\n",
    "train_samples = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e13e4",
   "metadata": {},
   "source": [
    "### Data Creation\n",
    "\n",
    "For this simple task, we'll be creating our own example data set.\n",
    "\n",
    "As motivation for this data, let's suppose that an experimental drug was tested on individuals ranging from age 13 to 100 in a clinical trial. The trial had **2100** participants. Half of the participants were under 65 years old, and the other half was 65 years of age or older.\n",
    "\n",
    "The trial showed that around 95% of patients 65 or older experienced side effects from the drug, and around 95% of patients under 65 experienced no side effects, generally showing that elderly individuals were more likely to experience side effects.\n",
    "\n",
    "Ultimately, we want to build a model to tell us whether or not a patient will experience side effects solely based on the patient's age. The judgement of the model will be based on the training data.\n",
    "\n",
    "**Labels:**\n",
    "- 1: patient did experience side effects\n",
    "- 0: patient didnÂ´t experience side effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d22aef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    # The ~5% of younger individuals who did experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(1)\n",
    "\n",
    "    # The ~5% of older individuals who did not experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(0)\n",
    "\n",
    "for i in range(1000):\n",
    "    # The ~95% of younger individuals who did not experience side effects\n",
    "    random_younger = randint(13,64)\n",
    "    train_samples.append(random_younger)\n",
    "    train_labels.append(0)\n",
    "\n",
    "    # The ~95% of older individuals who did experience side effects\n",
    "    random_older = randint(65,100)\n",
    "    train_samples.append(random_older)\n",
    "    train_labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cd795",
   "metadata": {},
   "source": [
    "This is what the train_samples data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d588ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "89\n",
      "18\n",
      "78\n",
      "42\n",
      "75\n",
      "19\n",
      "95\n",
      "55\n",
      "82\n",
      "34\n",
      "78\n",
      "50\n",
      "66\n",
      "52\n",
      "93\n",
      "63\n",
      "81\n",
      "22\n",
      "83\n",
      "32\n",
      "77\n",
      "59\n",
      "75\n",
      "34\n",
      "88\n",
      "43\n",
      "97\n",
      "39\n",
      "81\n",
      "38\n",
      "90\n",
      "62\n",
      "70\n",
      "14\n",
      "87\n",
      "20\n",
      "95\n",
      "48\n",
      "84\n",
      "24\n",
      "76\n",
      "40\n",
      "97\n",
      "60\n",
      "87\n",
      "39\n",
      "79\n",
      "27\n",
      "91\n",
      "13\n",
      "76\n",
      "31\n",
      "91\n",
      "26\n",
      "78\n",
      "17\n",
      "66\n",
      "33\n",
      "83\n",
      "35\n",
      "94\n",
      "38\n",
      "99\n",
      "34\n",
      "89\n",
      "49\n",
      "85\n",
      "38\n",
      "94\n",
      "49\n",
      "69\n",
      "33\n",
      "74\n",
      "45\n",
      "67\n",
      "60\n",
      "94\n",
      "32\n",
      "89\n",
      "38\n",
      "93\n",
      "60\n",
      "84\n",
      "60\n",
      "82\n",
      "44\n",
      "69\n",
      "43\n",
      "77\n",
      "45\n",
      "87\n",
      "45\n",
      "88\n",
      "50\n",
      "87\n",
      "31\n",
      "93\n",
      "60\n",
      "85\n",
      "64\n",
      "83\n",
      "18\n",
      "92\n",
      "46\n",
      "82\n",
      "34\n",
      "93\n",
      "51\n",
      "65\n",
      "46\n",
      "78\n",
      "54\n",
      "77\n",
      "56\n",
      "98\n",
      "53\n",
      "94\n",
      "27\n",
      "68\n",
      "17\n",
      "87\n",
      "23\n",
      "76\n",
      "48\n",
      "77\n",
      "29\n",
      "70\n",
      "62\n",
      "85\n",
      "59\n",
      "93\n",
      "56\n",
      "72\n",
      "26\n",
      "99\n",
      "13\n",
      "95\n",
      "20\n",
      "65\n",
      "48\n",
      "95\n",
      "40\n",
      "85\n",
      "63\n",
      "87\n",
      "46\n",
      "96\n",
      "16\n",
      "71\n",
      "14\n",
      "65\n",
      "44\n",
      "81\n",
      "30\n",
      "76\n",
      "16\n",
      "86\n",
      "25\n",
      "79\n",
      "36\n",
      "91\n",
      "55\n",
      "87\n",
      "46\n",
      "65\n",
      "43\n",
      "77\n",
      "14\n",
      "83\n",
      "21\n",
      "96\n",
      "29\n",
      "90\n",
      "29\n",
      "98\n",
      "59\n",
      "95\n",
      "44\n",
      "88\n",
      "17\n",
      "94\n",
      "43\n",
      "84\n",
      "23\n",
      "99\n",
      "50\n",
      "95\n",
      "25\n",
      "72\n",
      "40\n",
      "83\n",
      "27\n",
      "91\n",
      "49\n",
      "97\n",
      "30\n",
      "89\n",
      "40\n",
      "67\n",
      "51\n",
      "100\n",
      "31\n",
      "88\n",
      "56\n",
      "78\n",
      "31\n",
      "86\n",
      "45\n",
      "82\n",
      "33\n",
      "87\n",
      "31\n",
      "92\n",
      "64\n",
      "91\n",
      "13\n",
      "67\n",
      "53\n",
      "95\n",
      "42\n",
      "89\n",
      "62\n",
      "85\n",
      "52\n",
      "83\n",
      "64\n",
      "86\n",
      "26\n",
      "80\n",
      "35\n",
      "88\n",
      "20\n",
      "78\n",
      "14\n",
      "67\n",
      "55\n",
      "65\n",
      "13\n",
      "84\n",
      "19\n",
      "78\n",
      "55\n",
      "67\n",
      "58\n",
      "82\n",
      "63\n",
      "77\n",
      "62\n",
      "100\n",
      "35\n",
      "67\n",
      "17\n",
      "65\n",
      "20\n",
      "70\n",
      "21\n",
      "75\n",
      "24\n",
      "89\n",
      "52\n",
      "77\n",
      "63\n",
      "98\n",
      "26\n",
      "90\n",
      "19\n",
      "100\n",
      "36\n",
      "73\n",
      "46\n",
      "93\n",
      "42\n",
      "72\n",
      "61\n",
      "87\n",
      "25\n",
      "93\n",
      "47\n",
      "77\n",
      "58\n",
      "79\n",
      "39\n",
      "76\n",
      "57\n",
      "79\n",
      "41\n",
      "85\n",
      "24\n",
      "86\n",
      "43\n",
      "98\n",
      "22\n",
      "95\n",
      "47\n",
      "96\n",
      "44\n",
      "84\n",
      "14\n",
      "94\n",
      "59\n",
      "75\n",
      "37\n",
      "67\n",
      "16\n",
      "95\n",
      "37\n",
      "65\n",
      "19\n",
      "98\n",
      "21\n",
      "91\n",
      "59\n",
      "100\n",
      "33\n",
      "65\n",
      "16\n",
      "93\n",
      "19\n",
      "81\n",
      "39\n",
      "94\n",
      "40\n",
      "67\n",
      "17\n",
      "74\n",
      "45\n",
      "70\n",
      "39\n",
      "66\n",
      "49\n",
      "77\n",
      "24\n",
      "92\n",
      "62\n",
      "70\n",
      "52\n",
      "75\n",
      "45\n",
      "92\n",
      "18\n",
      "96\n",
      "26\n",
      "88\n",
      "52\n",
      "73\n",
      "53\n",
      "68\n",
      "26\n",
      "83\n",
      "16\n",
      "83\n",
      "39\n",
      "65\n",
      "61\n",
      "85\n",
      "57\n",
      "89\n",
      "14\n",
      "81\n",
      "27\n",
      "65\n",
      "33\n",
      "77\n",
      "33\n",
      "71\n",
      "45\n",
      "100\n",
      "25\n",
      "96\n",
      "18\n",
      "81\n",
      "45\n",
      "95\n",
      "39\n",
      "78\n",
      "62\n",
      "91\n",
      "25\n",
      "79\n",
      "42\n",
      "80\n",
      "19\n",
      "91\n",
      "17\n",
      "78\n",
      "25\n",
      "73\n",
      "40\n",
      "79\n",
      "48\n",
      "85\n",
      "40\n",
      "79\n",
      "33\n",
      "65\n",
      "37\n",
      "87\n",
      "24\n",
      "99\n",
      "13\n",
      "90\n",
      "19\n",
      "69\n",
      "20\n",
      "74\n",
      "38\n",
      "98\n",
      "51\n",
      "96\n",
      "53\n",
      "76\n",
      "46\n",
      "77\n",
      "17\n",
      "80\n",
      "32\n",
      "85\n",
      "64\n",
      "89\n",
      "43\n",
      "66\n",
      "15\n",
      "74\n",
      "49\n",
      "71\n",
      "22\n",
      "94\n",
      "31\n",
      "93\n",
      "17\n",
      "92\n",
      "16\n",
      "67\n",
      "59\n",
      "72\n",
      "43\n",
      "79\n",
      "52\n",
      "97\n",
      "55\n",
      "87\n",
      "52\n",
      "67\n",
      "24\n",
      "90\n",
      "35\n",
      "73\n",
      "32\n",
      "65\n",
      "16\n",
      "76\n",
      "33\n",
      "89\n",
      "15\n",
      "89\n",
      "47\n",
      "95\n",
      "22\n",
      "72\n",
      "36\n",
      "84\n",
      "19\n",
      "91\n",
      "56\n",
      "94\n",
      "58\n",
      "83\n",
      "57\n",
      "99\n",
      "33\n",
      "92\n",
      "27\n",
      "89\n",
      "13\n",
      "99\n",
      "45\n",
      "96\n",
      "60\n",
      "96\n",
      "58\n",
      "76\n",
      "32\n",
      "77\n",
      "56\n",
      "78\n",
      "25\n",
      "89\n",
      "22\n",
      "79\n",
      "41\n",
      "66\n",
      "60\n",
      "75\n",
      "13\n",
      "87\n",
      "54\n",
      "84\n",
      "26\n",
      "96\n",
      "42\n",
      "90\n",
      "36\n",
      "85\n",
      "33\n",
      "74\n",
      "26\n",
      "74\n",
      "24\n",
      "73\n",
      "58\n",
      "73\n",
      "24\n",
      "93\n",
      "17\n",
      "69\n",
      "53\n",
      "86\n",
      "50\n",
      "68\n",
      "39\n",
      "71\n",
      "61\n",
      "83\n",
      "13\n",
      "100\n",
      "13\n",
      "70\n",
      "40\n",
      "90\n",
      "53\n",
      "89\n",
      "59\n",
      "73\n",
      "27\n",
      "82\n",
      "16\n",
      "73\n",
      "28\n",
      "84\n",
      "58\n",
      "85\n",
      "46\n",
      "74\n",
      "27\n",
      "95\n",
      "22\n",
      "100\n",
      "48\n",
      "84\n",
      "22\n",
      "79\n",
      "39\n",
      "94\n",
      "43\n",
      "92\n",
      "19\n",
      "80\n",
      "32\n",
      "88\n",
      "17\n",
      "91\n",
      "61\n",
      "68\n",
      "51\n",
      "97\n",
      "57\n",
      "99\n",
      "36\n",
      "67\n",
      "13\n",
      "90\n",
      "28\n",
      "69\n",
      "31\n",
      "75\n",
      "29\n",
      "66\n",
      "26\n",
      "86\n",
      "18\n",
      "97\n",
      "33\n",
      "99\n",
      "33\n",
      "68\n",
      "43\n",
      "97\n",
      "22\n",
      "95\n",
      "34\n",
      "75\n",
      "22\n",
      "94\n",
      "29\n",
      "76\n",
      "58\n",
      "75\n",
      "35\n",
      "88\n",
      "23\n",
      "85\n",
      "31\n",
      "80\n",
      "53\n",
      "100\n",
      "53\n",
      "66\n",
      "36\n",
      "73\n",
      "27\n",
      "98\n",
      "58\n",
      "84\n",
      "47\n",
      "75\n",
      "58\n",
      "98\n",
      "26\n",
      "93\n",
      "56\n",
      "70\n",
      "40\n",
      "79\n",
      "33\n",
      "94\n",
      "29\n",
      "69\n",
      "56\n",
      "99\n",
      "18\n",
      "91\n",
      "37\n",
      "79\n",
      "40\n",
      "98\n",
      "23\n",
      "98\n",
      "33\n",
      "92\n",
      "55\n",
      "69\n",
      "58\n",
      "98\n",
      "55\n",
      "81\n",
      "40\n",
      "92\n",
      "62\n",
      "70\n",
      "61\n",
      "83\n",
      "21\n",
      "96\n",
      "25\n",
      "78\n",
      "18\n",
      "65\n",
      "50\n",
      "73\n",
      "39\n",
      "82\n",
      "51\n",
      "73\n",
      "47\n",
      "79\n",
      "40\n",
      "68\n",
      "22\n",
      "89\n",
      "36\n",
      "98\n",
      "55\n",
      "92\n",
      "14\n",
      "99\n",
      "47\n",
      "83\n",
      "41\n",
      "88\n",
      "41\n",
      "91\n",
      "59\n",
      "77\n",
      "50\n",
      "99\n",
      "34\n",
      "84\n",
      "24\n",
      "88\n",
      "54\n",
      "98\n",
      "61\n",
      "65\n",
      "41\n",
      "95\n",
      "18\n",
      "85\n",
      "51\n",
      "82\n",
      "40\n",
      "94\n",
      "64\n",
      "86\n",
      "30\n",
      "93\n",
      "20\n",
      "99\n",
      "47\n",
      "70\n",
      "60\n",
      "97\n",
      "45\n",
      "76\n",
      "17\n",
      "96\n",
      "39\n",
      "100\n",
      "43\n",
      "95\n",
      "54\n",
      "70\n",
      "52\n",
      "65\n",
      "49\n",
      "83\n",
      "45\n",
      "71\n",
      "41\n",
      "95\n",
      "57\n",
      "89\n",
      "38\n",
      "66\n",
      "44\n",
      "78\n",
      "64\n",
      "77\n",
      "25\n",
      "67\n",
      "28\n",
      "95\n",
      "58\n",
      "93\n",
      "45\n",
      "97\n",
      "44\n",
      "70\n",
      "63\n",
      "97\n",
      "45\n",
      "68\n",
      "62\n",
      "66\n",
      "47\n",
      "82\n",
      "22\n",
      "89\n",
      "32\n",
      "69\n",
      "21\n",
      "78\n",
      "46\n",
      "77\n",
      "47\n",
      "76\n",
      "25\n",
      "68\n",
      "25\n",
      "100\n",
      "57\n",
      "100\n",
      "55\n",
      "65\n",
      "45\n",
      "76\n",
      "40\n",
      "84\n",
      "64\n",
      "93\n",
      "26\n",
      "97\n",
      "39\n",
      "89\n",
      "59\n",
      "71\n",
      "15\n",
      "90\n",
      "21\n",
      "99\n",
      "18\n",
      "89\n",
      "19\n",
      "80\n",
      "56\n",
      "70\n",
      "58\n",
      "94\n",
      "60\n",
      "84\n",
      "28\n",
      "67\n",
      "44\n",
      "86\n",
      "50\n",
      "97\n",
      "18\n",
      "90\n",
      "34\n",
      "65\n",
      "46\n",
      "92\n",
      "63\n",
      "94\n",
      "44\n",
      "93\n",
      "20\n",
      "77\n",
      "58\n",
      "68\n",
      "45\n",
      "98\n",
      "41\n",
      "85\n",
      "38\n",
      "95\n",
      "30\n",
      "88\n",
      "32\n",
      "94\n",
      "32\n",
      "87\n",
      "25\n",
      "99\n",
      "38\n",
      "82\n",
      "41\n",
      "74\n",
      "57\n",
      "94\n",
      "30\n",
      "65\n",
      "30\n",
      "75\n",
      "64\n",
      "77\n",
      "25\n",
      "89\n",
      "63\n",
      "94\n",
      "34\n",
      "90\n",
      "64\n",
      "67\n",
      "63\n",
      "99\n",
      "16\n",
      "80\n",
      "53\n",
      "87\n",
      "23\n",
      "69\n",
      "50\n",
      "94\n",
      "52\n",
      "75\n",
      "24\n",
      "98\n",
      "30\n",
      "97\n",
      "48\n",
      "79\n",
      "26\n",
      "65\n",
      "17\n",
      "70\n",
      "32\n",
      "82\n",
      "39\n",
      "98\n",
      "16\n",
      "74\n",
      "49\n",
      "87\n",
      "62\n",
      "80\n",
      "20\n",
      "82\n",
      "26\n",
      "91\n",
      "33\n",
      "74\n",
      "48\n",
      "95\n",
      "59\n",
      "94\n",
      "51\n",
      "83\n",
      "38\n",
      "93\n",
      "18\n",
      "66\n",
      "60\n",
      "88\n",
      "52\n",
      "99\n",
      "16\n",
      "68\n",
      "30\n",
      "89\n",
      "23\n",
      "91\n",
      "39\n",
      "78\n",
      "57\n",
      "72\n",
      "60\n",
      "76\n",
      "50\n",
      "76\n",
      "39\n",
      "92\n",
      "22\n",
      "100\n",
      "38\n",
      "85\n",
      "56\n",
      "73\n",
      "32\n",
      "71\n",
      "15\n",
      "97\n",
      "18\n",
      "72\n",
      "62\n",
      "93\n",
      "52\n",
      "90\n",
      "36\n",
      "99\n",
      "13\n",
      "78\n",
      "25\n",
      "81\n",
      "48\n",
      "73\n",
      "15\n",
      "87\n",
      "15\n",
      "77\n",
      "54\n",
      "80\n",
      "63\n",
      "79\n",
      "61\n",
      "74\n",
      "16\n",
      "100\n",
      "25\n",
      "98\n",
      "17\n",
      "81\n",
      "46\n",
      "94\n",
      "44\n",
      "100\n",
      "52\n",
      "70\n",
      "59\n",
      "96\n",
      "43\n",
      "69\n",
      "20\n",
      "97\n",
      "44\n",
      "78\n",
      "13\n",
      "90\n",
      "24\n",
      "70\n",
      "55\n",
      "88\n",
      "33\n",
      "96\n",
      "30\n",
      "83\n",
      "41\n",
      "69\n",
      "56\n",
      "73\n",
      "45\n",
      "87\n",
      "31\n",
      "99\n",
      "37\n",
      "75\n",
      "30\n",
      "69\n",
      "38\n",
      "81\n",
      "61\n",
      "96\n",
      "17\n",
      "92\n",
      "18\n",
      "93\n",
      "28\n",
      "87\n",
      "59\n",
      "69\n",
      "48\n",
      "78\n",
      "27\n",
      "65\n",
      "22\n",
      "69\n",
      "47\n",
      "97\n",
      "36\n",
      "76\n",
      "44\n",
      "78\n",
      "57\n",
      "76\n",
      "33\n",
      "84\n",
      "55\n",
      "69\n",
      "56\n",
      "100\n",
      "27\n",
      "87\n",
      "39\n",
      "89\n",
      "55\n",
      "78\n",
      "18\n",
      "84\n",
      "25\n",
      "70\n",
      "56\n",
      "72\n",
      "58\n",
      "83\n",
      "41\n",
      "83\n",
      "44\n",
      "87\n",
      "37\n",
      "67\n",
      "48\n",
      "88\n",
      "22\n",
      "100\n",
      "53\n",
      "84\n",
      "43\n",
      "90\n",
      "63\n",
      "74\n",
      "17\n",
      "90\n",
      "16\n",
      "65\n",
      "48\n",
      "91\n",
      "60\n",
      "89\n",
      "45\n",
      "70\n",
      "50\n",
      "86\n",
      "38\n",
      "89\n",
      "17\n",
      "91\n",
      "34\n",
      "65\n",
      "64\n",
      "100\n",
      "42\n",
      "88\n",
      "14\n",
      "78\n",
      "40\n",
      "86\n",
      "43\n",
      "67\n",
      "64\n",
      "87\n",
      "14\n",
      "78\n",
      "57\n",
      "90\n",
      "60\n",
      "88\n",
      "45\n",
      "65\n",
      "29\n",
      "97\n",
      "26\n",
      "81\n",
      "48\n",
      "88\n",
      "63\n",
      "84\n",
      "40\n",
      "72\n",
      "13\n",
      "94\n",
      "45\n",
      "92\n",
      "44\n",
      "71\n",
      "24\n",
      "83\n",
      "42\n",
      "100\n",
      "30\n",
      "71\n",
      "24\n",
      "92\n",
      "21\n",
      "85\n",
      "47\n",
      "97\n",
      "19\n",
      "65\n",
      "49\n",
      "98\n",
      "48\n",
      "90\n",
      "40\n",
      "91\n",
      "20\n",
      "95\n",
      "22\n",
      "71\n",
      "56\n",
      "88\n",
      "49\n",
      "66\n",
      "36\n",
      "82\n",
      "18\n",
      "67\n",
      "46\n",
      "81\n",
      "22\n",
      "77\n",
      "61\n",
      "68\n",
      "36\n",
      "74\n",
      "36\n",
      "81\n",
      "54\n",
      "65\n",
      "51\n",
      "93\n",
      "54\n",
      "87\n",
      "21\n",
      "86\n",
      "41\n",
      "73\n",
      "58\n",
      "80\n",
      "61\n",
      "94\n",
      "23\n",
      "78\n",
      "36\n",
      "68\n",
      "55\n",
      "89\n",
      "20\n",
      "89\n",
      "41\n",
      "82\n",
      "42\n",
      "74\n",
      "55\n",
      "98\n",
      "61\n",
      "72\n",
      "41\n",
      "82\n",
      "26\n",
      "79\n",
      "24\n",
      "93\n",
      "33\n",
      "85\n",
      "47\n",
      "92\n",
      "44\n",
      "74\n",
      "27\n",
      "68\n",
      "30\n",
      "83\n",
      "31\n",
      "88\n",
      "21\n",
      "73\n",
      "56\n",
      "82\n",
      "17\n",
      "97\n",
      "14\n",
      "81\n",
      "50\n",
      "86\n",
      "13\n",
      "87\n",
      "42\n",
      "71\n",
      "39\n",
      "68\n",
      "60\n",
      "91\n",
      "48\n",
      "74\n",
      "26\n",
      "72\n",
      "14\n",
      "77\n",
      "64\n",
      "74\n",
      "28\n",
      "97\n",
      "32\n",
      "74\n",
      "32\n",
      "85\n",
      "61\n",
      "77\n",
      "56\n",
      "70\n",
      "23\n",
      "78\n",
      "27\n",
      "81\n",
      "32\n",
      "73\n",
      "31\n",
      "93\n",
      "52\n",
      "77\n",
      "22\n",
      "95\n",
      "21\n",
      "85\n",
      "32\n",
      "91\n",
      "34\n",
      "74\n",
      "36\n",
      "90\n",
      "63\n",
      "72\n",
      "24\n",
      "95\n",
      "54\n",
      "79\n",
      "60\n",
      "98\n",
      "34\n",
      "94\n",
      "30\n",
      "87\n",
      "41\n",
      "94\n",
      "62\n",
      "90\n",
      "36\n",
      "86\n",
      "64\n",
      "70\n",
      "37\n",
      "69\n",
      "29\n",
      "81\n",
      "59\n",
      "69\n",
      "22\n",
      "67\n",
      "23\n",
      "86\n",
      "46\n",
      "89\n",
      "57\n",
      "100\n",
      "49\n",
      "88\n",
      "44\n",
      "94\n",
      "62\n",
      "82\n",
      "58\n",
      "76\n",
      "46\n",
      "93\n",
      "23\n",
      "99\n",
      "34\n",
      "95\n",
      "13\n",
      "82\n",
      "36\n",
      "70\n",
      "19\n",
      "87\n",
      "49\n",
      "89\n",
      "46\n",
      "79\n",
      "22\n",
      "95\n",
      "31\n",
      "69\n",
      "56\n",
      "99\n",
      "15\n",
      "95\n",
      "53\n",
      "68\n",
      "44\n",
      "74\n",
      "61\n",
      "97\n",
      "53\n",
      "95\n",
      "55\n",
      "95\n",
      "27\n",
      "97\n",
      "57\n",
      "76\n",
      "22\n",
      "77\n",
      "16\n",
      "95\n",
      "54\n",
      "68\n",
      "42\n",
      "96\n",
      "41\n",
      "87\n",
      "23\n",
      "78\n",
      "18\n",
      "66\n",
      "35\n",
      "94\n",
      "40\n",
      "89\n",
      "26\n",
      "66\n",
      "63\n",
      "97\n",
      "29\n",
      "100\n",
      "63\n",
      "74\n",
      "30\n",
      "78\n",
      "36\n",
      "82\n",
      "18\n",
      "86\n",
      "64\n",
      "96\n",
      "15\n",
      "98\n",
      "27\n",
      "86\n",
      "58\n",
      "89\n",
      "18\n",
      "70\n",
      "43\n",
      "79\n",
      "49\n",
      "100\n",
      "32\n",
      "76\n",
      "30\n",
      "77\n",
      "44\n",
      "68\n",
      "19\n",
      "73\n",
      "25\n",
      "68\n",
      "48\n",
      "84\n",
      "25\n",
      "100\n",
      "30\n",
      "87\n",
      "38\n",
      "82\n",
      "60\n",
      "70\n",
      "52\n",
      "65\n",
      "14\n",
      "99\n",
      "20\n",
      "75\n",
      "25\n",
      "83\n",
      "37\n",
      "77\n",
      "26\n",
      "73\n",
      "17\n",
      "72\n",
      "25\n",
      "95\n",
      "39\n",
      "83\n",
      "57\n",
      "95\n",
      "56\n",
      "75\n",
      "24\n",
      "65\n",
      "62\n",
      "95\n",
      "29\n",
      "70\n",
      "61\n",
      "71\n",
      "31\n",
      "100\n",
      "31\n",
      "81\n",
      "55\n",
      "75\n",
      "57\n",
      "81\n",
      "22\n",
      "67\n",
      "26\n",
      "77\n",
      "36\n",
      "89\n",
      "50\n",
      "67\n",
      "16\n",
      "70\n",
      "18\n",
      "96\n",
      "63\n",
      "94\n",
      "41\n",
      "77\n",
      "45\n",
      "70\n",
      "22\n",
      "71\n",
      "60\n",
      "100\n",
      "15\n",
      "67\n",
      "46\n",
      "93\n",
      "21\n",
      "92\n",
      "56\n",
      "89\n",
      "32\n",
      "84\n",
      "29\n",
      "86\n",
      "14\n",
      "74\n",
      "36\n",
      "96\n",
      "32\n",
      "98\n",
      "17\n",
      "95\n",
      "57\n",
      "83\n",
      "58\n",
      "88\n",
      "33\n",
      "92\n",
      "30\n",
      "87\n",
      "52\n",
      "86\n",
      "55\n",
      "89\n",
      "55\n",
      "93\n",
      "19\n",
      "70\n",
      "63\n",
      "96\n",
      "61\n",
      "65\n",
      "58\n",
      "76\n",
      "33\n",
      "97\n",
      "58\n",
      "88\n",
      "14\n",
      "95\n",
      "51\n",
      "82\n",
      "13\n",
      "95\n",
      "59\n",
      "65\n",
      "27\n",
      "91\n",
      "28\n",
      "76\n",
      "51\n",
      "91\n",
      "35\n",
      "77\n",
      "42\n",
      "72\n",
      "33\n",
      "87\n",
      "42\n",
      "92\n",
      "62\n",
      "79\n",
      "38\n",
      "66\n",
      "60\n",
      "88\n",
      "59\n",
      "79\n",
      "40\n",
      "100\n",
      "57\n",
      "92\n",
      "44\n",
      "93\n",
      "38\n",
      "95\n",
      "33\n",
      "87\n",
      "14\n",
      "94\n",
      "41\n",
      "87\n",
      "63\n",
      "100\n",
      "61\n",
      "75\n",
      "16\n",
      "91\n",
      "13\n",
      "66\n",
      "35\n",
      "98\n",
      "52\n",
      "89\n",
      "26\n",
      "72\n",
      "43\n",
      "70\n",
      "57\n",
      "89\n",
      "36\n",
      "91\n",
      "22\n",
      "99\n",
      "23\n",
      "96\n",
      "19\n",
      "95\n",
      "15\n",
      "73\n",
      "35\n",
      "99\n",
      "24\n",
      "67\n",
      "13\n",
      "98\n",
      "36\n",
      "74\n",
      "55\n",
      "91\n",
      "55\n",
      "84\n",
      "20\n",
      "65\n",
      "54\n",
      "88\n",
      "38\n",
      "85\n",
      "35\n",
      "91\n",
      "29\n",
      "98\n",
      "33\n",
      "73\n",
      "61\n",
      "86\n",
      "36\n",
      "83\n",
      "53\n",
      "74\n",
      "14\n",
      "93\n",
      "32\n",
      "100\n",
      "32\n",
      "91\n",
      "18\n",
      "83\n",
      "46\n",
      "73\n",
      "57\n",
      "93\n",
      "26\n",
      "66\n",
      "26\n",
      "74\n",
      "40\n",
      "78\n",
      "21\n",
      "86\n",
      "21\n",
      "67\n",
      "44\n",
      "89\n",
      "45\n",
      "95\n",
      "30\n",
      "96\n",
      "45\n",
      "73\n",
      "22\n",
      "94\n",
      "55\n",
      "70\n",
      "40\n",
      "88\n",
      "47\n",
      "84\n",
      "51\n",
      "85\n",
      "46\n",
      "94\n",
      "38\n",
      "81\n",
      "48\n",
      "94\n",
      "14\n",
      "74\n",
      "48\n",
      "91\n",
      "43\n",
      "82\n",
      "34\n",
      "73\n",
      "15\n",
      "72\n",
      "16\n",
      "75\n",
      "64\n",
      "83\n",
      "16\n",
      "88\n",
      "43\n",
      "82\n",
      "18\n",
      "75\n",
      "15\n",
      "87\n",
      "52\n",
      "89\n",
      "49\n",
      "71\n",
      "19\n",
      "86\n",
      "42\n",
      "99\n",
      "26\n",
      "86\n",
      "40\n",
      "82\n",
      "14\n",
      "85\n",
      "56\n",
      "71\n",
      "20\n",
      "98\n",
      "18\n",
      "78\n",
      "20\n",
      "91\n",
      "24\n",
      "78\n",
      "45\n",
      "96\n",
      "42\n",
      "75\n",
      "44\n",
      "83\n",
      "24\n",
      "91\n",
      "45\n",
      "71\n",
      "35\n",
      "87\n",
      "32\n",
      "75\n",
      "27\n",
      "69\n",
      "42\n",
      "92\n",
      "32\n",
      "77\n",
      "37\n",
      "71\n",
      "25\n",
      "98\n",
      "29\n",
      "95\n",
      "34\n",
      "85\n",
      "51\n",
      "82\n",
      "33\n",
      "100\n",
      "24\n",
      "97\n",
      "49\n",
      "73\n",
      "50\n",
      "75\n",
      "15\n",
      "99\n",
      "44\n",
      "89\n",
      "20\n",
      "67\n",
      "22\n",
      "93\n",
      "32\n",
      "76\n",
      "48\n",
      "96\n",
      "55\n",
      "94\n",
      "60\n",
      "86\n",
      "41\n",
      "91\n",
      "56\n",
      "99\n",
      "62\n",
      "96\n",
      "37\n",
      "75\n",
      "49\n",
      "88\n",
      "17\n",
      "78\n",
      "56\n",
      "85\n",
      "53\n",
      "78\n",
      "46\n",
      "89\n",
      "28\n",
      "84\n",
      "21\n",
      "86\n",
      "30\n",
      "82\n",
      "43\n",
      "79\n",
      "26\n",
      "98\n",
      "39\n",
      "88\n",
      "46\n",
      "98\n",
      "17\n",
      "95\n",
      "62\n",
      "84\n",
      "28\n",
      "100\n",
      "16\n",
      "74\n",
      "40\n",
      "80\n",
      "62\n",
      "82\n",
      "36\n",
      "81\n",
      "62\n",
      "85\n",
      "44\n",
      "70\n",
      "39\n",
      "74\n",
      "16\n",
      "84\n",
      "20\n",
      "86\n",
      "33\n",
      "97\n",
      "23\n",
      "100\n",
      "32\n",
      "85\n",
      "30\n",
      "72\n",
      "40\n",
      "100\n",
      "33\n",
      "90\n",
      "40\n",
      "90\n",
      "64\n",
      "67\n",
      "20\n",
      "67\n",
      "43\n",
      "89\n",
      "62\n",
      "74\n",
      "28\n",
      "78\n",
      "55\n",
      "70\n",
      "56\n",
      "99\n",
      "21\n",
      "78\n",
      "22\n",
      "95\n",
      "30\n",
      "72\n",
      "54\n",
      "74\n",
      "37\n",
      "90\n",
      "16\n",
      "75\n",
      "36\n",
      "80\n",
      "27\n",
      "67\n",
      "28\n",
      "72\n",
      "14\n",
      "87\n",
      "63\n",
      "90\n",
      "57\n",
      "88\n",
      "42\n",
      "84\n",
      "52\n",
      "97\n",
      "29\n",
      "93\n",
      "30\n",
      "98\n",
      "18\n",
      "68\n",
      "54\n",
      "66\n",
      "21\n",
      "83\n",
      "58\n",
      "68\n",
      "14\n",
      "75\n",
      "16\n",
      "83\n",
      "44\n",
      "89\n",
      "32\n",
      "79\n",
      "54\n",
      "92\n",
      "19\n",
      "96\n",
      "25\n",
      "90\n",
      "49\n",
      "70\n",
      "56\n",
      "79\n",
      "22\n",
      "89\n",
      "13\n",
      "100\n",
      "48\n",
      "65\n",
      "35\n",
      "94\n",
      "59\n",
      "67\n",
      "47\n",
      "98\n",
      "34\n",
      "95\n",
      "56\n",
      "100\n",
      "27\n",
      "95\n",
      "37\n",
      "74\n",
      "29\n",
      "67\n",
      "23\n",
      "93\n",
      "16\n",
      "96\n",
      "62\n",
      "76\n",
      "31\n",
      "93\n",
      "54\n",
      "67\n",
      "49\n",
      "77\n",
      "25\n",
      "98\n",
      "43\n",
      "72\n",
      "58\n",
      "92\n",
      "54\n",
      "93\n",
      "24\n",
      "93\n",
      "44\n",
      "67\n",
      "48\n",
      "98\n",
      "41\n",
      "86\n",
      "19\n",
      "97\n",
      "36\n",
      "70\n",
      "18\n",
      "78\n",
      "60\n",
      "67\n",
      "18\n",
      "77\n",
      "55\n",
      "97\n",
      "31\n",
      "82\n",
      "26\n",
      "72\n",
      "39\n",
      "76\n",
      "53\n",
      "96\n",
      "53\n",
      "99\n",
      "46\n",
      "84\n",
      "34\n",
      "87\n",
      "42\n",
      "96\n",
      "60\n",
      "96\n",
      "62\n",
      "85\n",
      "14\n",
      "93\n",
      "18\n",
      "73\n",
      "35\n",
      "93\n",
      "15\n",
      "81\n",
      "27\n",
      "89\n",
      "61\n",
      "79\n",
      "51\n",
      "76\n",
      "47\n",
      "75\n",
      "54\n",
      "83\n",
      "58\n",
      "97\n",
      "31\n",
      "65\n",
      "27\n",
      "90\n",
      "58\n",
      "78\n",
      "41\n",
      "81\n",
      "23\n",
      "72\n",
      "14\n",
      "92\n",
      "24\n",
      "95\n",
      "37\n",
      "94\n",
      "48\n",
      "94\n",
      "47\n",
      "98\n",
      "24\n",
      "98\n",
      "45\n",
      "89\n",
      "40\n",
      "98\n",
      "41\n",
      "77\n",
      "40\n",
      "70\n",
      "29\n",
      "66\n",
      "22\n",
      "87\n",
      "34\n",
      "75\n",
      "16\n",
      "65\n",
      "64\n",
      "91\n",
      "31\n",
      "67\n",
      "62\n",
      "96\n",
      "14\n",
      "66\n",
      "15\n",
      "88\n",
      "47\n",
      "86\n",
      "22\n",
      "99\n",
      "15\n",
      "96\n",
      "24\n",
      "93\n",
      "49\n",
      "88\n",
      "21\n",
      "89\n",
      "64\n",
      "79\n",
      "49\n",
      "94\n",
      "39\n",
      "67\n",
      "63\n",
      "97\n",
      "53\n",
      "87\n",
      "37\n",
      "77\n",
      "43\n",
      "79\n",
      "22\n",
      "91\n",
      "14\n",
      "73\n",
      "60\n",
      "73\n",
      "19\n",
      "67\n",
      "48\n",
      "71\n",
      "55\n",
      "87\n",
      "63\n",
      "78\n",
      "61\n",
      "86\n",
      "48\n",
      "94\n",
      "30\n",
      "91\n",
      "21\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for i in train_samples:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551f5441",
   "metadata": {},
   "source": [
    "This is what the train_labels look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "741b4369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in train_labels:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84be618",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "\n",
    "We now convert both lists into numpy arrays due to what we discussed the fit() function expects, and we then shuffle the arrays to remove any order that was imposed on the data during the creation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bb777d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels)\n",
    "train_samples = np.array(train_samples)\n",
    "train_labels, train_samples = shuffle(train_labels, train_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed820583",
   "metadata": {},
   "source": [
    "In this form, we now have the ability to pass the data to the model because it is now in the required format, however, before doing that, we'll first scale the data down to a range from 0 to 1.\n",
    "\n",
    "We'll use **scikit-learn's MinMaxScaler class** to scale all of the data down from a scale ranging from 13 to 100 to be on a scale from 0 to 1.\n",
    "\n",
    "We reshape the data as a technical requirement just since the **fit_transform()** function doesn't accept 1D data by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b8787b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f53304",
   "metadata": {},
   "source": [
    "Now that the data has been scaled, let's iterate over the scaled data to see what it looks like now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a90e9b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97701149]\n",
      "[0.22988506]\n",
      "[0.85057471]\n",
      "[0.71264368]\n",
      "[0.90804598]\n",
      "[0.98850575]\n",
      "[0.26436782]\n",
      "[1.]\n",
      "[0.59770115]\n",
      "[0.52873563]\n",
      "[0.5862069]\n",
      "[0.90804598]\n",
      "[1.]\n",
      "[0.90804598]\n",
      "[0.37931034]\n",
      "[0.42528736]\n",
      "[0.66666667]\n",
      "[0.11494253]\n",
      "[0.16091954]\n",
      "[0.50574713]\n",
      "[0.93103448]\n",
      "[0.71264368]\n",
      "[0.52873563]\n",
      "[0.03448276]\n",
      "[0.8045977]\n",
      "[0.3908046]\n",
      "[0.31034483]\n",
      "[0.35632184]\n",
      "[0.72413793]\n",
      "[0.70114943]\n",
      "[0.82758621]\n",
      "[0.26436782]\n",
      "[0.72413793]\n",
      "[0.10344828]\n",
      "[0.93103448]\n",
      "[0.05747126]\n",
      "[0.83908046]\n",
      "[0.16091954]\n",
      "[0.10344828]\n",
      "[0.55172414]\n",
      "[0.96551724]\n",
      "[1.]\n",
      "[0.22988506]\n",
      "[1.]\n",
      "[0.06896552]\n",
      "[0.10344828]\n",
      "[0.33333333]\n",
      "[0.16091954]\n",
      "[0.89655172]\n",
      "[0.6091954]\n",
      "[0.81609195]\n",
      "[0.44827586]\n",
      "[0.8045977]\n",
      "[0.03448276]\n",
      "[0.27586207]\n",
      "[0.83908046]\n",
      "[0.33333333]\n",
      "[1.]\n",
      "[0.03448276]\n",
      "[0.56321839]\n",
      "[0.97701149]\n",
      "[0.67816092]\n",
      "[0.45977011]\n",
      "[0.4137931]\n",
      "[0.98850575]\n",
      "[0.32183908]\n",
      "[0.36781609]\n",
      "[0.]\n",
      "[0.09195402]\n",
      "[0.36781609]\n",
      "[0.13793103]\n",
      "[0.09195402]\n",
      "[0.04597701]\n",
      "[0.43678161]\n",
      "[0.]\n",
      "[0.49425287]\n",
      "[0.62068966]\n",
      "[0.89655172]\n",
      "[0.63218391]\n",
      "[0.16091954]\n",
      "[0.56321839]\n",
      "[0.97701149]\n",
      "[0.81609195]\n",
      "[0.04597701]\n",
      "[0.08045977]\n",
      "[0.51724138]\n",
      "[0.2183908]\n",
      "[0.31034483]\n",
      "[0.55172414]\n",
      "[0.59770115]\n",
      "[0.1954023]\n",
      "[0.56321839]\n",
      "[0.74712644]\n",
      "[0.3908046]\n",
      "[0.75862069]\n",
      "[0.52873563]\n",
      "[0.04597701]\n",
      "[0.10344828]\n",
      "[0.57471264]\n",
      "[0.50574713]\n",
      "[0.17241379]\n",
      "[0.5862069]\n",
      "[0.68965517]\n",
      "[0.10344828]\n",
      "[0.74712644]\n",
      "[0.6091954]\n",
      "[0.97701149]\n",
      "[0.79310345]\n",
      "[0.94252874]\n",
      "[0.95402299]\n",
      "[0.66666667]\n",
      "[0.91954023]\n",
      "[0.49425287]\n",
      "[0.87356322]\n",
      "[0.48275862]\n",
      "[0.73563218]\n",
      "[0.2183908]\n",
      "[0.98850575]\n",
      "[0.31034483]\n",
      "[0.37931034]\n",
      "[0.97701149]\n",
      "[0.28735632]\n",
      "[0.97701149]\n",
      "[0.88505747]\n",
      "[0.87356322]\n",
      "[0.31034483]\n",
      "[0.63218391]\n",
      "[0.34482759]\n",
      "[0.10344828]\n",
      "[0.43678161]\n",
      "[0.8045977]\n",
      "[0.8045977]\n",
      "[0.65517241]\n",
      "[0.94252874]\n",
      "[0.85057471]\n",
      "[0.51724138]\n",
      "[0.57471264]\n",
      "[0.3908046]\n",
      "[0.62068966]\n",
      "[0.81609195]\n",
      "[0.91954023]\n",
      "[0.96551724]\n",
      "[0.49425287]\n",
      "[0.02298851]\n",
      "[0.44827586]\n",
      "[0.01149425]\n",
      "[0.90804598]\n",
      "[0.89655172]\n",
      "[0.87356322]\n",
      "[0.74712644]\n",
      "[0.45977011]\n",
      "[0.89655172]\n",
      "[0.62068966]\n",
      "[0.73563218]\n",
      "[0.03448276]\n",
      "[0.57471264]\n",
      "[0.57471264]\n",
      "[0.16091954]\n",
      "[0.28735632]\n",
      "[0.74712644]\n",
      "[0.11494253]\n",
      "[0.44827586]\n",
      "[0.50574713]\n",
      "[0.18390805]\n",
      "[0.01149425]\n",
      "[0.11494253]\n",
      "[0.89655172]\n",
      "[0.48275862]\n",
      "[0.71264368]\n",
      "[0.65517241]\n",
      "[0.4137931]\n",
      "[0.18390805]\n",
      "[0.90804598]\n",
      "[1.]\n",
      "[0.91954023]\n",
      "[0.63218391]\n",
      "[0.68965517]\n",
      "[0.73563218]\n",
      "[0.04597701]\n",
      "[0.87356322]\n",
      "[0.93103448]\n",
      "[0.55172414]\n",
      "[0.50574713]\n",
      "[0.87356322]\n",
      "[0.88505747]\n",
      "[0.18390805]\n",
      "[0.47126437]\n",
      "[0.89655172]\n",
      "[0.62068966]\n",
      "[0.87356322]\n",
      "[0.8045977]\n",
      "[0.10344828]\n",
      "[0.62068966]\n",
      "[0.34482759]\n",
      "[0.73563218]\n",
      "[0.29885057]\n",
      "[0.86206897]\n",
      "[0.72413793]\n",
      "[0.70114943]\n",
      "[0.75862069]\n",
      "[0.55172414]\n",
      "[0.97701149]\n",
      "[0.33333333]\n",
      "[0.70114943]\n",
      "[0.87356322]\n",
      "[0.52873563]\n",
      "[0.4137931]\n",
      "[0.42528736]\n",
      "[0.37931034]\n",
      "[0.35632184]\n",
      "[0.93103448]\n",
      "[0.59770115]\n",
      "[0.40229885]\n",
      "[0.89655172]\n",
      "[0.3908046]\n",
      "[0.1954023]\n",
      "[0.5862069]\n",
      "[0.04597701]\n",
      "[0.98850575]\n",
      "[0.95402299]\n",
      "[0.94252874]\n",
      "[0.96551724]\n",
      "[0.82758621]\n",
      "[0.6091954]\n",
      "[0.87356322]\n",
      "[0.97701149]\n",
      "[0.64367816]\n",
      "[0.44827586]\n",
      "[0.90804598]\n",
      "[0.91954023]\n",
      "[0.27586207]\n",
      "[0.10344828]\n",
      "[0.97701149]\n",
      "[0.79310345]\n",
      "[0.85057471]\n",
      "[0.73563218]\n",
      "[0.68965517]\n",
      "[0.01149425]\n",
      "[0.12643678]\n",
      "[0.35632184]\n",
      "[0.98850575]\n",
      "[0.97701149]\n",
      "[0.7816092]\n",
      "[0.10344828]\n",
      "[0.63218391]\n",
      "[0.91954023]\n",
      "[0.35632184]\n",
      "[0.63218391]\n",
      "[0.37931034]\n",
      "[0.48275862]\n",
      "[0.8045977]\n",
      "[0.63218391]\n",
      "[0.89655172]\n",
      "[0.18390805]\n",
      "[0.68965517]\n",
      "[0.02298851]\n",
      "[0.40229885]\n",
      "[0.89655172]\n",
      "[0.65517241]\n",
      "[0.71264368]\n",
      "[0.44827586]\n",
      "[0.62068966]\n",
      "[0.]\n",
      "[0.59770115]\n",
      "[0.66666667]\n",
      "[0.79310345]\n",
      "[0.10344828]\n",
      "[0.29885057]\n",
      "[0.7816092]\n",
      "[0.51724138]\n",
      "[0.70114943]\n",
      "[0.93103448]\n",
      "[0.34482759]\n",
      "[0.86206897]\n",
      "[0.57471264]\n",
      "[0.57471264]\n",
      "[0.91954023]\n",
      "[0.28735632]\n",
      "[0.68965517]\n",
      "[0.32183908]\n",
      "[0.27586207]\n",
      "[0.14942529]\n",
      "[0.55172414]\n",
      "[0.88505747]\n",
      "[0.63218391]\n",
      "[0.50574713]\n",
      "[0.82758621]\n",
      "[0.27586207]\n",
      "[0.1954023]\n",
      "[0.35632184]\n",
      "[0.32183908]\n",
      "[0.34482759]\n",
      "[0.5862069]\n",
      "[0.95402299]\n",
      "[0.49425287]\n",
      "[0.11494253]\n",
      "[0.35632184]\n",
      "[0.4137931]\n",
      "[0.66666667]\n",
      "[0.59770115]\n",
      "[0.55172414]\n",
      "[0.85057471]\n",
      "[0.68965517]\n",
      "[0.62068966]\n",
      "[0.93103448]\n",
      "[0.96551724]\n",
      "[0.82758621]\n",
      "[0.48275862]\n",
      "[0.97701149]\n",
      "[0.91954023]\n",
      "[0.54022989]\n",
      "[0.36781609]\n",
      "[0.47126437]\n",
      "[0.74712644]\n",
      "[0.02298851]\n",
      "[0.01149425]\n",
      "[0.]\n",
      "[0.22988506]\n",
      "[0.83908046]\n",
      "[0.90804598]\n",
      "[0.2183908]\n",
      "[0.08045977]\n",
      "[0.59770115]\n",
      "[0.36781609]\n",
      "[0.45977011]\n",
      "[0.54022989]\n",
      "[0.62068966]\n",
      "[0.95402299]\n",
      "[0.97701149]\n",
      "[0.48275862]\n",
      "[0.91954023]\n",
      "[0.45977011]\n",
      "[0.33333333]\n",
      "[0.73563218]\n",
      "[0.75862069]\n",
      "[0.63218391]\n",
      "[0.]\n",
      "[0.75862069]\n",
      "[0.87356322]\n",
      "[0.96551724]\n",
      "[0.68965517]\n",
      "[0.48275862]\n",
      "[0.74712644]\n",
      "[0.75862069]\n",
      "[0.55172414]\n",
      "[0.62068966]\n",
      "[0.49425287]\n",
      "[0.88505747]\n",
      "[0.91954023]\n",
      "[0.63218391]\n",
      "[0.71264368]\n",
      "[0.62068966]\n",
      "[0.13793103]\n",
      "[0.51724138]\n",
      "[0.73563218]\n",
      "[0.1954023]\n",
      "[0.20689655]\n",
      "[0.34482759]\n",
      "[0.62068966]\n",
      "[0.86206897]\n",
      "[0.62068966]\n",
      "[0.10344828]\n",
      "[0.49425287]\n",
      "[0.96551724]\n",
      "[0.18390805]\n",
      "[0.54022989]\n",
      "[0.31034483]\n",
      "[0.47126437]\n",
      "[0.26436782]\n",
      "[0.73563218]\n",
      "[0.71264368]\n",
      "[0.08045977]\n",
      "[0.13793103]\n",
      "[0.8045977]\n",
      "[0.48275862]\n",
      "[0.25287356]\n",
      "[0.83908046]\n",
      "[0.10344828]\n",
      "[0.98850575]\n",
      "[0.40229885]\n",
      "[0.26436782]\n",
      "[0.93103448]\n",
      "[0.48275862]\n",
      "[0.16091954]\n",
      "[0.3908046]\n",
      "[0.96551724]\n",
      "[0.67816092]\n",
      "[0.72413793]\n",
      "[0.62068966]\n",
      "[0.56321839]\n",
      "[0.82758621]\n",
      "[0.34482759]\n",
      "[0.54022989]\n",
      "[0.5862069]\n",
      "[0.94252874]\n",
      "[0.91954023]\n",
      "[0.34482759]\n",
      "[0.94252874]\n",
      "[0.81609195]\n",
      "[0.05747126]\n",
      "[0.5862069]\n",
      "[0.95402299]\n",
      "[0.32183908]\n",
      "[0.29885057]\n",
      "[0.34482759]\n",
      "[0.44827586]\n",
      "[1.]\n",
      "[0.2183908]\n",
      "[0.11494253]\n",
      "[0.83908046]\n",
      "[0.54022989]\n",
      "[0.91954023]\n",
      "[0.75862069]\n",
      "[0.82758621]\n",
      "[0.95402299]\n",
      "[0.11494253]\n",
      "[0.04597701]\n",
      "[0.86206897]\n",
      "[0.03448276]\n",
      "[0.47126437]\n",
      "[0.8045977]\n",
      "[0.75862069]\n",
      "[0.96551724]\n",
      "[0.01149425]\n",
      "[0.08045977]\n",
      "[0.94252874]\n",
      "[0.12643678]\n",
      "[0.94252874]\n",
      "[0.68965517]\n",
      "[0.14942529]\n",
      "[0.52873563]\n",
      "[0.35632184]\n",
      "[0.6091954]\n",
      "[0.31034483]\n",
      "[0.7816092]\n",
      "[0.93103448]\n",
      "[0.20689655]\n",
      "[0.93103448]\n",
      "[0.51724138]\n",
      "[0.88505747]\n",
      "[0.8045977]\n",
      "[0.70114943]\n",
      "[0.32183908]\n",
      "[0.77011494]\n",
      "[0.31034483]\n",
      "[0.14942529]\n",
      "[0.7816092]\n",
      "[0.05747126]\n",
      "[0.94252874]\n",
      "[0.79310345]\n",
      "[1.]\n",
      "[0.12643678]\n",
      "[0.7816092]\n",
      "[0.51724138]\n",
      "[0.79310345]\n",
      "[0.97701149]\n",
      "[0.8045977]\n",
      "[0.04597701]\n",
      "[0.74712644]\n",
      "[0.94252874]\n",
      "[0.29885057]\n",
      "[0.83908046]\n",
      "[0.7816092]\n",
      "[0.62068966]\n",
      "[0.59770115]\n",
      "[0.26436782]\n",
      "[0.93103448]\n",
      "[0.44827586]\n",
      "[0.32183908]\n",
      "[0.]\n",
      "[0.79310345]\n",
      "[0.72413793]\n",
      "[0.14942529]\n",
      "[0.82758621]\n",
      "[0.91954023]\n",
      "[0.8045977]\n",
      "[0.06896552]\n",
      "[0.04597701]\n",
      "[0.]\n",
      "[0.73563218]\n",
      "[0.17241379]\n",
      "[0.2183908]\n",
      "[0.29885057]\n",
      "[0.4137931]\n",
      "[0.55172414]\n",
      "[0.22988506]\n",
      "[0.72413793]\n",
      "[0.29885057]\n",
      "[0.4137931]\n",
      "[0.64367816]\n",
      "[0.2183908]\n",
      "[0.7816092]\n",
      "[0.71264368]\n",
      "[0.71264368]\n",
      "[0.59770115]\n",
      "[0.27586207]\n",
      "[0.94252874]\n",
      "[0.98850575]\n",
      "[0.08045977]\n",
      "[0.48275862]\n",
      "[0.45977011]\n",
      "[0.40229885]\n",
      "[0.67816092]\n",
      "[0.22988506]\n",
      "[0.66666667]\n",
      "[0.7816092]\n",
      "[0.04597701]\n",
      "[0.71264368]\n",
      "[0.26436782]\n",
      "[0.56321839]\n",
      "[0.74712644]\n",
      "[0.24137931]\n",
      "[0.91954023]\n",
      "[0.05747126]\n",
      "[0.68965517]\n",
      "[0.37931034]\n",
      "[0.2183908]\n",
      "[0.73563218]\n",
      "[0.77011494]\n",
      "[0.70114943]\n",
      "[0.13793103]\n",
      "[0.94252874]\n",
      "[0.48275862]\n",
      "[0.06896552]\n",
      "[0.65517241]\n",
      "[0.34482759]\n",
      "[0.65517241]\n",
      "[0.31034483]\n",
      "[0.81609195]\n",
      "[0.94252874]\n",
      "[0.81609195]\n",
      "[0.96551724]\n",
      "[0.97701149]\n",
      "[0.88505747]\n",
      "[0.1954023]\n",
      "[0.01149425]\n",
      "[0.48275862]\n",
      "[0.49425287]\n",
      "[0.01149425]\n",
      "[0.36781609]\n",
      "[0.32183908]\n",
      "[0.34482759]\n",
      "[0.59770115]\n",
      "[0.51724138]\n",
      "[0.98850575]\n",
      "[0.65517241]\n",
      "[0.03448276]\n",
      "[0.16091954]\n",
      "[0.09195402]\n",
      "[0.68965517]\n",
      "[0.91954023]\n",
      "[0.89655172]\n",
      "[0.1954023]\n",
      "[0.83908046]\n",
      "[0.4137931]\n",
      "[0.18390805]\n",
      "[0.91954023]\n",
      "[0.83908046]\n",
      "[0.71264368]\n",
      "[0.59770115]\n",
      "[0.95402299]\n",
      "[0.29885057]\n",
      "[0.29885057]\n",
      "[0.93103448]\n",
      "[0.70114943]\n",
      "[0.70114943]\n",
      "[0.63218391]\n",
      "[0.90804598]\n",
      "[0.8045977]\n",
      "[0.37931034]\n",
      "[0.81609195]\n",
      "[0.75862069]\n",
      "[0.59770115]\n",
      "[0.86206897]\n",
      "[0.65517241]\n",
      "[0.6091954]\n",
      "[0.59770115]\n",
      "[0.89655172]\n",
      "[0.62068966]\n",
      "[0.81609195]\n",
      "[0.7816092]\n",
      "[1.]\n",
      "[0.97701149]\n",
      "[0.67816092]\n",
      "[0.4137931]\n",
      "[0.73563218]\n",
      "[0.8045977]\n",
      "[0.95402299]\n",
      "[0.33333333]\n",
      "[0.75862069]\n",
      "[0.13793103]\n",
      "[0.08045977]\n",
      "[0.10344828]\n",
      "[0.55172414]\n",
      "[0.31034483]\n",
      "[0.94252874]\n",
      "[0.04597701]\n",
      "[0.51724138]\n",
      "[0.25287356]\n",
      "[0.93103448]\n",
      "[0.5862069]\n",
      "[0.1954023]\n",
      "[0.83908046]\n",
      "[0.82758621]\n",
      "[0.08045977]\n",
      "[0.27586207]\n",
      "[0.98850575]\n",
      "[0.65517241]\n",
      "[0.63218391]\n",
      "[0.14942529]\n",
      "[0.29885057]\n",
      "[0.25287356]\n",
      "[0.89655172]\n",
      "[0.56321839]\n",
      "[0.09195402]\n",
      "[0.82758621]\n",
      "[0.05747126]\n",
      "[0.90804598]\n",
      "[0.73563218]\n",
      "[0.95402299]\n",
      "[0.77011494]\n",
      "[0.64367816]\n",
      "[0.94252874]\n",
      "[0.54022989]\n",
      "[0.12643678]\n",
      "[0.88505747]\n",
      "[0.22988506]\n",
      "[0.20689655]\n",
      "[0.09195402]\n",
      "[0.45977011]\n",
      "[0.75862069]\n",
      "[0.70114943]\n",
      "[0.86206897]\n",
      "[0.45977011]\n",
      "[0.85057471]\n",
      "[0.63218391]\n",
      "[0.1954023]\n",
      "[0.32183908]\n",
      "[0.06896552]\n",
      "[0.51724138]\n",
      "[0.05747126]\n",
      "[0.98850575]\n",
      "[0.95402299]\n",
      "[0.6091954]\n",
      "[0.18390805]\n",
      "[0.86206897]\n",
      "[0.04597701]\n",
      "[0.40229885]\n",
      "[0.25287356]\n",
      "[0.98850575]\n",
      "[0.56321839]\n",
      "[0.86206897]\n",
      "[0.25287356]\n",
      "[0.87356322]\n",
      "[0.59770115]\n",
      "[0.54022989]\n",
      "[0.31034483]\n",
      "[0.05747126]\n",
      "[0.85057471]\n",
      "[0.02298851]\n",
      "[0.59770115]\n",
      "[0.10344828]\n",
      "[0.64367816]\n",
      "[0.51724138]\n",
      "[0.50574713]\n",
      "[0.81609195]\n",
      "[0.06896552]\n",
      "[0.85057471]\n",
      "[0.8045977]\n",
      "[0.83908046]\n",
      "[0.91954023]\n",
      "[0.6091954]\n",
      "[0.]\n",
      "[0.12643678]\n",
      "[0.81609195]\n",
      "[0.85057471]\n",
      "[0.04597701]\n",
      "[0.8045977]\n",
      "[0.85057471]\n",
      "[0.94252874]\n",
      "[0.85057471]\n",
      "[0.25287356]\n",
      "[0.8045977]\n",
      "[0.98850575]\n",
      "[0.06896552]\n",
      "[0.45977011]\n",
      "[0.91954023]\n",
      "[0.86206897]\n",
      "[0.09195402]\n",
      "[0.57471264]\n",
      "[0.08045977]\n",
      "[0.98850575]\n",
      "[0.04597701]\n",
      "[0.17241379]\n",
      "[0.96551724]\n",
      "[0.7816092]\n",
      "[0.04597701]\n",
      "[0.95402299]\n",
      "[0.88505747]\n",
      "[0.93103448]\n",
      "[0.51724138]\n",
      "[0.29885057]\n",
      "[0.73563218]\n",
      "[0.75862069]\n",
      "[0.67816092]\n",
      "[0.31034483]\n",
      "[0.89655172]\n",
      "[0.88505747]\n",
      "[0.59770115]\n",
      "[0.72413793]\n",
      "[0.18390805]\n",
      "[0.8045977]\n",
      "[0.65517241]\n",
      "[0.36781609]\n",
      "[0.90804598]\n",
      "[0.17241379]\n",
      "[0.87356322]\n",
      "[0.52873563]\n",
      "[0.50574713]\n",
      "[0.14942529]\n",
      "[0.74712644]\n",
      "[0.05747126]\n",
      "[0.5862069]\n",
      "[0.98850575]\n",
      "[0.87356322]\n",
      "[0.96551724]\n",
      "[0.86206897]\n",
      "[0.89655172]\n",
      "[0.36781609]\n",
      "[0.6091954]\n",
      "[0.22988506]\n",
      "[0.85057471]\n",
      "[0.]\n",
      "[0.13793103]\n",
      "[0.01149425]\n",
      "[0.14942529]\n",
      "[0.74712644]\n",
      "[0.70114943]\n",
      "[0.87356322]\n",
      "[0.75862069]\n",
      "[0.35632184]\n",
      "[0.73563218]\n",
      "[0.10344828]\n",
      "[0.54022989]\n",
      "[0.20689655]\n",
      "[0.28735632]\n",
      "[1.]\n",
      "[0.64367816]\n",
      "[0.7816092]\n",
      "[0.73563218]\n",
      "[0.65517241]\n",
      "[0.90804598]\n",
      "[0.65517241]\n",
      "[0.5862069]\n",
      "[0.71264368]\n",
      "[0.82758621]\n",
      "[0.59770115]\n",
      "[0.63218391]\n",
      "[1.]\n",
      "[0.03448276]\n",
      "[0.16091954]\n",
      "[0.62068966]\n",
      "[0.73563218]\n",
      "[0.02298851]\n",
      "[0.2183908]\n",
      "[0.04597701]\n",
      "[0.73563218]\n",
      "[0.02298851]\n",
      "[0.34482759]\n",
      "[0.12643678]\n",
      "[0.57471264]\n",
      "[0.51724138]\n",
      "[0.11494253]\n",
      "[0.98850575]\n",
      "[0.87356322]\n",
      "[0.22988506]\n",
      "[0.94252874]\n",
      "[0.43678161]\n",
      "[0.35632184]\n",
      "[0.91954023]\n",
      "[0.25287356]\n",
      "[0.09195402]\n",
      "[0.89655172]\n",
      "[0.62068966]\n",
      "[0.29885057]\n",
      "[0.88505747]\n",
      "[0.70114943]\n",
      "[0.36781609]\n",
      "[0.1954023]\n",
      "[0.40229885]\n",
      "[0.8045977]\n",
      "[0.34482759]\n",
      "[0.94252874]\n",
      "[0.28735632]\n",
      "[0.65517241]\n",
      "[0.71264368]\n",
      "[0.14942529]\n",
      "[0.12643678]\n",
      "[0.79310345]\n",
      "[0.11494253]\n",
      "[0.35632184]\n",
      "[0.02298851]\n",
      "[0.90804598]\n",
      "[0.50574713]\n",
      "[0.22988506]\n",
      "[0.43678161]\n",
      "[0.02298851]\n",
      "[0.16091954]\n",
      "[0.22988506]\n",
      "[0.70114943]\n",
      "[0.36781609]\n",
      "[0.85057471]\n",
      "[0.64367816]\n",
      "[0.89655172]\n",
      "[0.85057471]\n",
      "[0.65517241]\n",
      "[0.3908046]\n",
      "[0.03448276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06896552]\n",
      "[0.05747126]\n",
      "[0.68965517]\n",
      "[0.91954023]\n",
      "[0.79310345]\n",
      "[1.]\n",
      "[0.65517241]\n",
      "[0.5862069]\n",
      "[0.42528736]\n",
      "[0.72413793]\n",
      "[0.16091954]\n",
      "[0.03448276]\n",
      "[0.72413793]\n",
      "[0.03448276]\n",
      "[0.7816092]\n",
      "[0.94252874]\n",
      "[0.54022989]\n",
      "[0.74712644]\n",
      "[0.66666667]\n",
      "[0.62068966]\n",
      "[1.]\n",
      "[0.05747126]\n",
      "[0.7816092]\n",
      "[0.35632184]\n",
      "[1.]\n",
      "[0.89655172]\n",
      "[0.67816092]\n",
      "[0.75862069]\n",
      "[0.25287356]\n",
      "[0.87356322]\n",
      "[0.5862069]\n",
      "[0.86206897]\n",
      "[0.95402299]\n",
      "[0.71264368]\n",
      "[0.52873563]\n",
      "[0.04597701]\n",
      "[0.48275862]\n",
      "[0.57471264]\n",
      "[0.47126437]\n",
      "[0.94252874]\n",
      "[0.36781609]\n",
      "[0.37931034]\n",
      "[0.65517241]\n",
      "[0.50574713]\n",
      "[0.03448276]\n",
      "[0.90804598]\n",
      "[0.68965517]\n",
      "[0.67816092]\n",
      "[0.97701149]\n",
      "[0.43678161]\n",
      "[0.94252874]\n",
      "[0.25287356]\n",
      "[0.51724138]\n",
      "[0.3908046]\n",
      "[0.11494253]\n",
      "[0.2183908]\n",
      "[0.20689655]\n",
      "[0.44827586]\n",
      "[0.93103448]\n",
      "[0.63218391]\n",
      "[0.12643678]\n",
      "[0.40229885]\n",
      "[0.94252874]\n",
      "[0.36781609]\n",
      "[0.96551724]\n",
      "[0.42528736]\n",
      "[0.35632184]\n",
      "[0.62068966]\n",
      "[0.31034483]\n",
      "[0.97701149]\n",
      "[0.09195402]\n",
      "[0.31034483]\n",
      "[0.6091954]\n",
      "[0.8045977]\n",
      "[0.77011494]\n",
      "[0.94252874]\n",
      "[0.85057471]\n",
      "[0.98850575]\n",
      "[0.14942529]\n",
      "[0.98850575]\n",
      "[0.87356322]\n",
      "[0.85057471]\n",
      "[0.64367816]\n",
      "[0.12643678]\n",
      "[0.96551724]\n",
      "[0.1954023]\n",
      "[0.54022989]\n",
      "[0.01149425]\n",
      "[0.95402299]\n",
      "[0.7816092]\n",
      "[0.90804598]\n",
      "[0.71264368]\n",
      "[0.22988506]\n",
      "[0.26436782]\n",
      "[0.89655172]\n",
      "[0.16091954]\n",
      "[0.54022989]\n",
      "[0.4137931]\n",
      "[0.3908046]\n",
      "[0.8045977]\n",
      "[0.14942529]\n",
      "[0.72413793]\n",
      "[0.59770115]\n",
      "[0.14942529]\n",
      "[0.20689655]\n",
      "[0.63218391]\n",
      "[0.87356322]\n",
      "[0.01149425]\n",
      "[0.71264368]\n",
      "[0.26436782]\n",
      "[0.54022989]\n",
      "[0.65517241]\n",
      "[0.68965517]\n",
      "[0.70114943]\n",
      "[0.48275862]\n",
      "[0.70114943]\n",
      "[0.94252874]\n",
      "[0.52873563]\n",
      "[0.74712644]\n",
      "[0.1954023]\n",
      "[0.90804598]\n",
      "[0.86206897]\n",
      "[0.87356322]\n",
      "[0.17241379]\n",
      "[0.50574713]\n",
      "[0.8045977]\n",
      "[0.18390805]\n",
      "[0.65517241]\n",
      "[0.82758621]\n",
      "[0.74712644]\n",
      "[0.57471264]\n",
      "[0.75862069]\n",
      "[0.65517241]\n",
      "[0.56321839]\n",
      "[0.48275862]\n",
      "[0.28735632]\n",
      "[0.37931034]\n",
      "[0.32183908]\n",
      "[0.55172414]\n",
      "[0.85057471]\n",
      "[0.88505747]\n",
      "[0.91954023]\n",
      "[0.40229885]\n",
      "[0.10344828]\n",
      "[0.86206897]\n",
      "[0.95402299]\n",
      "[0.5862069]\n",
      "[0.22988506]\n",
      "[0.93103448]\n",
      "[0.17241379]\n",
      "[0.6091954]\n",
      "[0.44827586]\n",
      "[0.74712644]\n",
      "[0.02298851]\n",
      "[0.64367816]\n",
      "[0.75862069]\n",
      "[0.44827586]\n",
      "[0.32183908]\n",
      "[0.98850575]\n",
      "[0.54022989]\n",
      "[0.24137931]\n",
      "[0.24137931]\n",
      "[0.43678161]\n",
      "[0.79310345]\n",
      "[0.29885057]\n",
      "[0.05747126]\n",
      "[0.64367816]\n",
      "[0.42528736]\n",
      "[0.97701149]\n",
      "[0.88505747]\n",
      "[0.83908046]\n",
      "[0.74712644]\n",
      "[0.22988506]\n",
      "[0.94252874]\n",
      "[0.22988506]\n",
      "[0.27586207]\n",
      "[0.7816092]\n",
      "[0.25287356]\n",
      "[0.]\n",
      "[0.96551724]\n",
      "[0.59770115]\n",
      "[0.05747126]\n",
      "[0.2183908]\n",
      "[0.66666667]\n",
      "[0.22988506]\n",
      "[0.43678161]\n",
      "[0.27586207]\n",
      "[0.48275862]\n",
      "[0.67816092]\n",
      "[1.]\n",
      "[0.66666667]\n",
      "[0.81609195]\n",
      "[0.16091954]\n",
      "[0.87356322]\n",
      "[0.1954023]\n",
      "[0.08045977]\n",
      "[1.]\n",
      "[0.67816092]\n",
      "[0.86206897]\n",
      "[0.59770115]\n",
      "[0.81609195]\n",
      "[0.34482759]\n",
      "[0.17241379]\n",
      "[0.91954023]\n",
      "[0.43678161]\n",
      "[0.32183908]\n",
      "[0.88505747]\n",
      "[0.88505747]\n",
      "[0.33333333]\n",
      "[0.06896552]\n",
      "[0.44827586]\n",
      "[0.73563218]\n",
      "[0.4137931]\n",
      "[1.]\n",
      "[0.1954023]\n",
      "[0.01149425]\n",
      "[0.49425287]\n",
      "[0.47126437]\n",
      "[0.11494253]\n",
      "[0.22988506]\n",
      "[1.]\n",
      "[0.57471264]\n",
      "[0.34482759]\n",
      "[0.74712644]\n",
      "[0.26436782]\n",
      "[0.70114943]\n",
      "[0.95402299]\n",
      "[0.28735632]\n",
      "[0.67816092]\n",
      "[0.68965517]\n",
      "[0.3908046]\n",
      "[0.97701149]\n",
      "[0.10344828]\n",
      "[0.28735632]\n",
      "[0.12643678]\n",
      "[0.65517241]\n",
      "[0.83908046]\n",
      "[0.5862069]\n",
      "[0.62068966]\n",
      "[0.87356322]\n",
      "[0.13793103]\n",
      "[0.95402299]\n",
      "[0.33333333]\n",
      "[0.29885057]\n",
      "[1.]\n",
      "[0.79310345]\n",
      "[0.79310345]\n",
      "[0.36781609]\n",
      "[0.40229885]\n",
      "[0.70114943]\n",
      "[0.45977011]\n",
      "[0.17241379]\n",
      "[0.13793103]\n",
      "[0.2183908]\n",
      "[0.79310345]\n",
      "[0.85057471]\n",
      "[0.57471264]\n",
      "[0.71264368]\n",
      "[0.2183908]\n",
      "[0.97701149]\n",
      "[0.56321839]\n",
      "[0.13793103]\n",
      "[0.14942529]\n",
      "[1.]\n",
      "[0.70114943]\n",
      "[0.29885057]\n",
      "[0.65517241]\n",
      "[0.66666667]\n",
      "[0.43678161]\n",
      "[0.96551724]\n",
      "[0.66666667]\n",
      "[0.98850575]\n",
      "[0.32183908]\n",
      "[0.81609195]\n",
      "[0.82758621]\n",
      "[0.44827586]\n",
      "[0.26436782]\n",
      "[0.67816092]\n",
      "[0.71264368]\n",
      "[0.86206897]\n",
      "[0.02298851]\n",
      "[0.88505747]\n",
      "[0.2183908]\n",
      "[0.73563218]\n",
      "[0.51724138]\n",
      "[0.49425287]\n",
      "[0.87356322]\n",
      "[0.13793103]\n",
      "[0.49425287]\n",
      "[0.8045977]\n",
      "[0.13793103]\n",
      "[0.44827586]\n",
      "[0.82758621]\n",
      "[0.87356322]\n",
      "[0.33333333]\n",
      "[0.81609195]\n",
      "[0.77011494]\n",
      "[0.24137931]\n",
      "[0.98850575]\n",
      "[0.74712644]\n",
      "[0.22988506]\n",
      "[0.86206897]\n",
      "[0.81609195]\n",
      "[0.56321839]\n",
      "[0.73563218]\n",
      "[0.68965517]\n",
      "[0.85057471]\n",
      "[0.4137931]\n",
      "[0.20689655]\n",
      "[0.66666667]\n",
      "[0.96551724]\n",
      "[0.26436782]\n",
      "[0.09195402]\n",
      "[0.26436782]\n",
      "[0.65517241]\n",
      "[0.6091954]\n",
      "[0.87356322]\n",
      "[0.2183908]\n",
      "[0.27586207]\n",
      "[0.77011494]\n",
      "[0.86206897]\n",
      "[0.74712644]\n",
      "[0.65517241]\n",
      "[0.88505747]\n",
      "[0.50574713]\n",
      "[0.86206897]\n",
      "[0.3908046]\n",
      "[0.08045977]\n",
      "[0.32183908]\n",
      "[0.79310345]\n",
      "[0.93103448]\n",
      "[0.17241379]\n",
      "[0.79310345]\n",
      "[0.86206897]\n",
      "[0.27586207]\n",
      "[0.73563218]\n",
      "[0.18390805]\n",
      "[0.03448276]\n",
      "[0.49425287]\n",
      "[0.2183908]\n",
      "[0.87356322]\n",
      "[0.72413793]\n",
      "[0.]\n",
      "[0.87356322]\n",
      "[0.26436782]\n",
      "[0.88505747]\n",
      "[0.14942529]\n",
      "[0.96551724]\n",
      "[0.03448276]\n",
      "[0.22988506]\n",
      "[0.08045977]\n",
      "[0.72413793]\n",
      "[0.05747126]\n",
      "[0.05747126]\n",
      "[0.]\n",
      "[0.10344828]\n",
      "[0.68965517]\n",
      "[0.37931034]\n",
      "[0.52873563]\n",
      "[0.89655172]\n",
      "[0.75862069]\n",
      "[1.]\n",
      "[0.85057471]\n",
      "[0.82758621]\n",
      "[0.88505747]\n",
      "[0.91954023]\n",
      "[0.06896552]\n",
      "[0.93103448]\n",
      "[0.10344828]\n",
      "[0.20689655]\n",
      "[0.50574713]\n",
      "[0.73563218]\n",
      "[0.79310345]\n",
      "[0.54022989]\n",
      "[0.68965517]\n",
      "[0.36781609]\n",
      "[0.93103448]\n",
      "[0.87356322]\n",
      "[0.62068966]\n",
      "[0.81609195]\n",
      "[0.55172414]\n",
      "[0.75862069]\n",
      "[0.51724138]\n",
      "[0.02298851]\n",
      "[0.47126437]\n",
      "[0.43678161]\n",
      "[0.01149425]\n",
      "[0.82758621]\n",
      "[0.95402299]\n",
      "[0.96551724]\n",
      "[0.52873563]\n",
      "[0.40229885]\n",
      "[1.]\n",
      "[0.50574713]\n",
      "[0.09195402]\n",
      "[0.74712644]\n",
      "[0.87356322]\n",
      "[0.71264368]\n",
      "[0.97701149]\n",
      "[0.32183908]\n",
      "[0.95402299]\n",
      "[0.83908046]\n",
      "[0.88505747]\n",
      "[0.82758621]\n",
      "[0.71264368]\n",
      "[0.70114943]\n",
      "[0.34482759]\n",
      "[0.56321839]\n",
      "[0.93103448]\n",
      "[0.02298851]\n",
      "[0.49425287]\n",
      "[0.55172414]\n",
      "[0.35632184]\n",
      "[0.34482759]\n",
      "[0.75862069]\n",
      "[0.67816092]\n",
      "[0.86206897]\n",
      "[0.95402299]\n",
      "[0.1954023]\n",
      "[0.77011494]\n",
      "[0.89655172]\n",
      "[0.87356322]\n",
      "[0.73563218]\n",
      "[1.]\n",
      "[0.90804598]\n",
      "[0.83908046]\n",
      "[0.56321839]\n",
      "[0.31034483]\n",
      "[0.75862069]\n",
      "[0.72413793]\n",
      "[0.34482759]\n",
      "[0.75862069]\n",
      "[0.12643678]\n",
      "[0.56321839]\n",
      "[0.28735632]\n",
      "[0.24137931]\n",
      "[0.02298851]\n",
      "[0.5862069]\n",
      "[0.79310345]\n",
      "[0.2183908]\n",
      "[0.01149425]\n",
      "[0.01149425]\n",
      "[0.89655172]\n",
      "[0.37931034]\n",
      "[0.54022989]\n",
      "[0.50574713]\n",
      "[0.49425287]\n",
      "[0.14942529]\n",
      "[0.1954023]\n",
      "[0.55172414]\n",
      "[0.29885057]\n",
      "[0.45977011]\n",
      "[0.22988506]\n",
      "[0.94252874]\n",
      "[0.44827586]\n",
      "[0.83908046]\n",
      "[0.66666667]\n",
      "[0.95402299]\n",
      "[0.62068966]\n",
      "[0.70114943]\n",
      "[0.96551724]\n",
      "[0.33333333]\n",
      "[0.35632184]\n",
      "[0.3908046]\n",
      "[0.55172414]\n",
      "[0.72413793]\n",
      "[0.20689655]\n",
      "[0.47126437]\n",
      "[0.7816092]\n",
      "[0.94252874]\n",
      "[0.29885057]\n",
      "[0.65517241]\n",
      "[0.22988506]\n",
      "[0.40229885]\n",
      "[0.31034483]\n",
      "[0.12643678]\n",
      "[0.64367816]\n",
      "[0.]\n",
      "[0.95402299]\n",
      "[0.64367816]\n",
      "[0.93103448]\n",
      "[0.6091954]\n",
      "[0.79310345]\n",
      "[0.98850575]\n",
      "[0.94252874]\n",
      "[0.14942529]\n",
      "[0.05747126]\n",
      "[0.95402299]\n",
      "[0.85057471]\n",
      "[0.98850575]\n",
      "[0.12643678]\n",
      "[0.13793103]\n",
      "[0.20689655]\n",
      "[0.05747126]\n",
      "[0.36781609]\n",
      "[0.94252874]\n",
      "[0.63218391]\n",
      "[0.28735632]\n",
      "[0.57471264]\n",
      "[0.33333333]\n",
      "[0.31034483]\n",
      "[0.62068966]\n",
      "[0.98850575]\n",
      "[0.13793103]\n",
      "[0.37931034]\n",
      "[0.40229885]\n",
      "[0.66666667]\n",
      "[0.94252874]\n",
      "[0.56321839]\n",
      "[0.13793103]\n",
      "[0.08045977]\n",
      "[0.64367816]\n",
      "[0.51724138]\n",
      "[0.2183908]\n",
      "[0.75862069]\n",
      "[0.36781609]\n",
      "[0.3908046]\n",
      "[0.93103448]\n",
      "[0.49425287]\n",
      "[0.83908046]\n",
      "[0.48275862]\n",
      "[0.47126437]\n",
      "[0.04597701]\n",
      "[0.88505747]\n",
      "[0.32183908]\n",
      "[0.43678161]\n",
      "[0.89655172]\n",
      "[0.33333333]\n",
      "[0.89655172]\n",
      "[0.7816092]\n",
      "[0.98850575]\n",
      "[0.90804598]\n",
      "[0.91954023]\n",
      "[0.59770115]\n",
      "[0.49425287]\n",
      "[0.70114943]\n",
      "[0.36781609]\n",
      "[0.35632184]\n",
      "[0.85057471]\n",
      "[0.70114943]\n",
      "[0.86206897]\n",
      "[0.94252874]\n",
      "[0.83908046]\n",
      "[0.83908046]\n",
      "[0.2183908]\n",
      "[0.7816092]\n",
      "[0.86206897]\n",
      "[0.89655172]\n",
      "[0.26436782]\n",
      "[0.96551724]\n",
      "[0.70114943]\n",
      "[0.10344828]\n",
      "[0.82758621]\n",
      "[0.75862069]\n",
      "[0.06896552]\n",
      "[0.31034483]\n",
      "[0.17241379]\n",
      "[0.83908046]\n",
      "[0.1954023]\n",
      "[0.25287356]\n",
      "[0.95402299]\n",
      "[0.22988506]\n",
      "[0.93103448]\n",
      "[0.02298851]\n",
      "[0.71264368]\n",
      "[0.62068966]\n",
      "[0.94252874]\n",
      "[0.56321839]\n",
      "[0.43678161]\n",
      "[0.4137931]\n",
      "[1.]\n",
      "[0.79310345]\n",
      "[0.33333333]\n",
      "[0.32183908]\n",
      "[0.83908046]\n",
      "[0.16091954]\n",
      "[0.06896552]\n",
      "[0.81609195]\n",
      "[0.82758621]\n",
      "[0.83908046]\n",
      "[0.50574713]\n",
      "[0.94252874]\n",
      "[0.16091954]\n",
      "[0.70114943]\n",
      "[0.87356322]\n",
      "[0.52873563]\n",
      "[0.91954023]\n",
      "[0.67816092]\n",
      "[0.34482759]\n",
      "[0.16091954]\n",
      "[0.45977011]\n",
      "[0.22988506]\n",
      "[0.01149425]\n",
      "[0.11494253]\n",
      "[0.12643678]\n",
      "[0.59770115]\n",
      "[0.1954023]\n",
      "[0.14942529]\n",
      "[0.36781609]\n",
      "[0.52873563]\n",
      "[0.01149425]\n",
      "[0.1954023]\n",
      "[0.25287356]\n",
      "[0.82758621]\n",
      "[0.81609195]\n",
      "[0.55172414]\n",
      "[0.6091954]\n",
      "[0.88505747]\n",
      "[0.24137931]\n",
      "[0.]\n",
      "[0.14942529]\n",
      "[0.87356322]\n",
      "[0.20689655]\n",
      "[0.54022989]\n",
      "[0.26436782]\n",
      "[0.44827586]\n",
      "[0.08045977]\n",
      "[0.36781609]\n",
      "[0.18390805]\n",
      "[0.75862069]\n",
      "[0.06896552]\n",
      "[0.71264368]\n",
      "[0.87356322]\n",
      "[0.6091954]\n",
      "[0.83908046]\n",
      "[0.68965517]\n",
      "[0.29885057]\n",
      "[0.98850575]\n",
      "[0.8045977]\n",
      "[0.82758621]\n",
      "[0.90804598]\n",
      "[0.26436782]\n",
      "[0.20689655]\n",
      "[0.70114943]\n",
      "[0.16091954]\n",
      "[0.77011494]\n",
      "[0.24137931]\n",
      "[0.31034483]\n",
      "[0.96551724]\n",
      "[0.49425287]\n",
      "[0.48275862]\n",
      "[0.16091954]\n",
      "[0.67816092]\n",
      "[0.]\n",
      "[0.85057471]\n",
      "[0.93103448]\n",
      "[0.05747126]\n",
      "[0.65517241]\n",
      "[0.59770115]\n",
      "[0.87356322]\n",
      "[0.91954023]\n",
      "[1.]\n",
      "[0.49425287]\n",
      "[0.67816092]\n",
      "[0.95402299]\n",
      "[0.52873563]\n",
      "[0.88505747]\n",
      "[0.]\n",
      "[0.55172414]\n",
      "[0.79310345]\n",
      "[0.22988506]\n",
      "[0.09195402]\n",
      "[0.]\n",
      "[0.65517241]\n",
      "[0.31034483]\n",
      "[0.12643678]\n",
      "[0.79310345]\n",
      "[0.72413793]\n",
      "[0.2183908]\n",
      "[0.36781609]\n",
      "[0.8045977]\n",
      "[0.26436782]\n",
      "[0.22988506]\n",
      "[0.59770115]\n",
      "[0.01149425]\n",
      "[0.24137931]\n",
      "[0.94252874]\n",
      "[0.98850575]\n",
      "[0.1954023]\n",
      "[0.67816092]\n",
      "[1.]\n",
      "[0.5862069]\n",
      "[1.]\n",
      "[0.72413793]\n",
      "[0.70114943]\n",
      "[0.1954023]\n",
      "[0.03448276]\n",
      "[0.04597701]\n",
      "[0.97701149]\n",
      "[0.14942529]\n",
      "[0.93103448]\n",
      "[0.27586207]\n",
      "[0.63218391]\n",
      "[0.70114943]\n",
      "[0.64367816]\n",
      "[0.5862069]\n",
      "[0.4137931]\n",
      "[0.74712644]\n",
      "[0.74712644]\n",
      "[0.77011494]\n",
      "[0.56321839]\n",
      "[0.72413793]\n",
      "[0.35632184]\n",
      "[0.74712644]\n",
      "[0.88505747]\n",
      "[0.10344828]\n",
      "[0.59770115]\n",
      "[0.29885057]\n",
      "[0.89655172]\n",
      "[0.03448276]\n",
      "[0.35632184]\n",
      "[0.86206897]\n",
      "[0.89655172]\n",
      "[0.59770115]\n",
      "[0.71264368]\n",
      "[0.06896552]\n",
      "[0.77011494]\n",
      "[0.67816092]\n",
      "[0.28735632]\n",
      "[0.97701149]\n",
      "[0.65517241]\n",
      "[0.48275862]\n",
      "[0.40229885]\n",
      "[0.97701149]\n",
      "[0.51724138]\n",
      "[0.40229885]\n",
      "[0.83908046]\n",
      "[0.51724138]\n",
      "[0.56321839]\n",
      "[0.16091954]\n",
      "[0.50574713]\n",
      "[0.93103448]\n",
      "[0.14942529]\n",
      "[0.20689655]\n",
      "[0.93103448]\n",
      "[0.14942529]\n",
      "[0.79310345]\n",
      "[0.03448276]\n",
      "[0.94252874]\n",
      "[0.77011494]\n",
      "[0.74712644]\n",
      "[0.20689655]\n",
      "[0.37931034]\n",
      "[0.94252874]\n",
      "[0.2183908]\n",
      "[0.12643678]\n",
      "[0.59770115]\n",
      "[0.62068966]\n",
      "[0.97701149]\n",
      "[0.74712644]\n",
      "[0.77011494]\n",
      "[0.44827586]\n",
      "[0.74712644]\n",
      "[0.48275862]\n",
      "[0.37931034]\n",
      "[0.91954023]\n",
      "[0.2183908]\n",
      "[0.28735632]\n",
      "[0.36781609]\n",
      "[0.12643678]\n",
      "[0.87356322]\n",
      "[0.86206897]\n",
      "[0.1954023]\n",
      "[0.87356322]\n",
      "[0.51724138]\n",
      "[0.08045977]\n",
      "[0.98850575]\n",
      "[0.6091954]\n",
      "[0.40229885]\n",
      "[0.47126437]\n",
      "[0.72413793]\n",
      "[0.82758621]\n",
      "[0.03448276]\n",
      "[0.49425287]\n",
      "[0.37931034]\n",
      "[0.90804598]\n",
      "[0.90804598]\n",
      "[0.86206897]\n",
      "[0.65517241]\n",
      "[0.54022989]\n",
      "[0.01149425]\n",
      "[0.82758621]\n",
      "[0.75862069]\n",
      "[0.13793103]\n",
      "[0.7816092]\n",
      "[0.97701149]\n",
      "[0.59770115]\n",
      "[0.40229885]\n",
      "[0.4137931]\n",
      "[0.20689655]\n",
      "[0.57471264]\n",
      "[0.48275862]\n",
      "[0.56321839]\n",
      "[0.09195402]\n",
      "[0.71264368]\n",
      "[0.98850575]\n",
      "[0.67816092]\n",
      "[0.59770115]\n",
      "[0.18390805]\n",
      "[0.51724138]\n",
      "[0.65517241]\n",
      "[0.56321839]\n",
      "[0.18390805]\n",
      "[0.14942529]\n",
      "[0.57471264]\n",
      "[0.81609195]\n",
      "[0.10344828]\n",
      "[0.74712644]\n",
      "[0.82758621]\n",
      "[1.]\n",
      "[0.48275862]\n",
      "[0.]\n",
      "[0.87356322]\n",
      "[0.62068966]\n",
      "[0.24137931]\n",
      "[0.83908046]\n",
      "[0.05747126]\n",
      "[0.57471264]\n",
      "[0.52873563]\n",
      "[0.68965517]\n",
      "[0.97701149]\n",
      "[0.43678161]\n",
      "[0.24137931]\n",
      "[0.24137931]\n",
      "[0.24137931]\n",
      "[0.98850575]\n",
      "[0.22988506]\n",
      "[0.90804598]\n",
      "[0.09195402]\n",
      "[0.31034483]\n",
      "[0.59770115]\n",
      "[0.03448276]\n",
      "[0.3908046]\n",
      "[0.73563218]\n",
      "[0.54022989]\n",
      "[0.6091954]\n",
      "[0.83908046]\n",
      "[0.45977011]\n",
      "[0.86206897]\n",
      "[0.68965517]\n",
      "[0.86206897]\n",
      "[0.40229885]\n",
      "[0.85057471]\n",
      "[0.03448276]\n",
      "[0.93103448]\n",
      "[0.74712644]\n",
      "[0.09195402]\n",
      "[0.57471264]\n",
      "[0.37931034]\n",
      "[0.51724138]\n",
      "[0.8045977]\n",
      "[0.36781609]\n",
      "[0.6091954]\n",
      "[0.91954023]\n",
      "[0.]\n",
      "[0.45977011]\n",
      "[0.36781609]\n",
      "[0.79310345]\n",
      "[0.35632184]\n",
      "[0.87356322]\n",
      "[0.36781609]\n",
      "[0.51724138]\n",
      "[0.79310345]\n",
      "[0.54022989]\n",
      "[0.54022989]\n",
      "[0.11494253]\n",
      "[0.64367816]\n",
      "[0.91954023]\n",
      "[0.95402299]\n",
      "[0.03448276]\n",
      "[0.12643678]\n",
      "[0.73563218]\n",
      "[0.24137931]\n",
      "[0.26436782]\n",
      "[0.93103448]\n",
      "[0.25287356]\n",
      "[0.42528736]\n",
      "[0.86206897]\n",
      "[0.3908046]\n",
      "[0.05747126]\n",
      "[0.62068966]\n",
      "[0.03448276]\n",
      "[0.04597701]\n",
      "[0.06896552]\n",
      "[0.72413793]\n",
      "[0.10344828]\n",
      "[0.85057471]\n",
      "[0.97701149]\n",
      "[0.91954023]\n",
      "[0.85057471]\n",
      "[0.95402299]\n",
      "[0.26436782]\n",
      "[1.]\n",
      "[0.85057471]\n",
      "[0.52873563]\n",
      "[0.24137931]\n",
      "[0.2183908]\n",
      "[0.48275862]\n",
      "[0.71264368]\n",
      "[0.96551724]\n",
      "[0.81609195]\n",
      "[0.7816092]\n",
      "[0.93103448]\n",
      "[0.73563218]\n",
      "[0.93103448]\n",
      "[0.37931034]\n",
      "[0.26436782]\n",
      "[0.55172414]\n",
      "[0.71264368]\n",
      "[0.06896552]\n",
      "[0.75862069]\n",
      "[0.12643678]\n",
      "[0.70114943]\n",
      "[0.59770115]\n",
      "[0.31034483]\n",
      "[0.97701149]\n",
      "[0.85057471]\n",
      "[0.33333333]\n",
      "[0.31034483]\n",
      "[0.3908046]\n",
      "[0.37931034]\n",
      "[0.26436782]\n",
      "[0.6091954]\n",
      "[0.59770115]\n",
      "[0.14942529]\n",
      "[0.62068966]\n",
      "[0.74712644]\n",
      "[0.74712644]\n",
      "[0.73563218]\n",
      "[0.73563218]\n",
      "[0.8045977]\n",
      "[0.62068966]\n",
      "[0.86206897]\n",
      "[0.65517241]\n",
      "[0.24137931]\n",
      "[0.35632184]\n",
      "[0.49425287]\n",
      "[0.13793103]\n",
      "[0.82758621]\n",
      "[0.37931034]\n",
      "[0.97701149]\n",
      "[0.56321839]\n",
      "[0.12643678]\n",
      "[0.81609195]\n",
      "[0.93103448]\n",
      "[0.26436782]\n",
      "[0.73563218]\n",
      "[0.94252874]\n",
      "[0.51724138]\n",
      "[0.33333333]\n",
      "[0.94252874]\n",
      "[0.2183908]\n",
      "[0.09195402]\n",
      "[0.12643678]\n",
      "[0.83908046]\n",
      "[0.87356322]\n",
      "[0.32183908]\n",
      "[0.12643678]\n",
      "[1.]\n",
      "[0.45977011]\n",
      "[0.13793103]\n",
      "[0.64367816]\n",
      "[0.49425287]\n",
      "[0.74712644]\n",
      "[0.36781609]\n",
      "[0.40229885]\n",
      "[0.29885057]\n",
      "[0.79310345]\n",
      "[0.82758621]\n",
      "[0.68965517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10344828]\n",
      "[0.04597701]\n",
      "[0.74712644]\n",
      "[0.44827586]\n",
      "[0.27586207]\n",
      "[0.05747126]\n",
      "[0.31034483]\n",
      "[0.32183908]\n",
      "[0.74712644]\n",
      "[0.71264368]\n",
      "[0.74712644]\n",
      "[0.73563218]\n",
      "[0.88505747]\n",
      "[0.73563218]\n",
      "[0.72413793]\n",
      "[0.90804598]\n",
      "[0.73563218]\n",
      "[0.81609195]\n",
      "[0.95402299]\n",
      "[0.12643678]\n",
      "[0.62068966]\n",
      "[0.05747126]\n",
      "[0.87356322]\n",
      "[0.27586207]\n",
      "[0.09195402]\n",
      "[0.44827586]\n",
      "[0.52873563]\n",
      "[0.08045977]\n",
      "[0.20689655]\n",
      "[0.05747126]\n",
      "[0.14942529]\n",
      "[0.42528736]\n",
      "[0.91954023]\n",
      "[0.34482759]\n",
      "[0.24137931]\n",
      "[0.13793103]\n",
      "[0.18390805]\n",
      "[0.3908046]\n",
      "[0.01149425]\n",
      "[0.65517241]\n",
      "[0.13793103]\n",
      "[0.24137931]\n",
      "[0.85057471]\n",
      "[0.74712644]\n",
      "[0.71264368]\n",
      "[0.87356322]\n",
      "[0.50574713]\n",
      "[0.29885057]\n",
      "[0.20689655]\n",
      "[0.85057471]\n",
      "[0.4137931]\n",
      "[0.67816092]\n",
      "[0.6091954]\n",
      "[0.97701149]\n",
      "[0.35632184]\n",
      "[0.64367816]\n",
      "[0.37931034]\n",
      "[0.35632184]\n",
      "[0.5862069]\n",
      "[0.45977011]\n",
      "[0.96551724]\n",
      "[0.90804598]\n",
      "[0.42528736]\n",
      "[0.08045977]\n",
      "[0.09195402]\n",
      "[0.68965517]\n",
      "[0.49425287]\n",
      "[0.28735632]\n",
      "[0.85057471]\n",
      "[0.89655172]\n",
      "[0.40229885]\n",
      "[0.66666667]\n",
      "[0.98850575]\n",
      "[0.10344828]\n",
      "[0.31034483]\n",
      "[0.48275862]\n",
      "[0.64367816]\n",
      "[0.70114943]\n",
      "[0.45977011]\n",
      "[0.97701149]\n",
      "[0.56321839]\n",
      "[0.10344828]\n",
      "[0.49425287]\n",
      "[0.88505747]\n",
      "[0.86206897]\n",
      "[0.81609195]\n",
      "[0.91954023]\n",
      "[0.01149425]\n",
      "[0.05747126]\n",
      "[0.27586207]\n",
      "[0.13793103]\n",
      "[0.32183908]\n",
      "[0.62068966]\n",
      "[0.63218391]\n",
      "[0.32183908]\n",
      "[0.75862069]\n",
      "[0.87356322]\n",
      "[0.03448276]\n",
      "[0.03448276]\n",
      "[0.93103448]\n",
      "[0.89655172]\n",
      "[0.59770115]\n",
      "[0.42528736]\n",
      "[0.63218391]\n",
      "[0.54022989]\n",
      "[0.94252874]\n",
      "[0.97701149]\n",
      "[0.62068966]\n",
      "[0.32183908]\n",
      "[0.93103448]\n",
      "[0.11494253]\n",
      "[0.68965517]\n",
      "[0.02298851]\n",
      "[0.94252874]\n",
      "[0.91954023]\n",
      "[0.13793103]\n",
      "[0.18390805]\n",
      "[0.47126437]\n",
      "[0.67816092]\n",
      "[0.93103448]\n",
      "[0.97701149]\n",
      "[0.75862069]\n",
      "[0.57471264]\n",
      "[0.85057471]\n",
      "[0.09195402]\n",
      "[0.63218391]\n",
      "[0.4137931]\n",
      "[0.49425287]\n",
      "[0.96551724]\n",
      "[0.94252874]\n",
      "[0.16091954]\n",
      "[0.66666667]\n",
      "[0.3908046]\n",
      "[0.35632184]\n",
      "[0.55172414]\n",
      "[0.16091954]\n",
      "[0.05747126]\n",
      "[0.05747126]\n",
      "[0.68965517]\n",
      "[0.94252874]\n",
      "[0.7816092]\n",
      "[0.79310345]\n",
      "[0.35632184]\n",
      "[0.55172414]\n",
      "[0.91954023]\n",
      "[0.28735632]\n",
      "[0.4137931]\n",
      "[0.50574713]\n",
      "[0.72413793]\n",
      "[0.8045977]\n",
      "[0.62068966]\n",
      "[0.89655172]\n",
      "[0.34482759]\n",
      "[0.49425287]\n",
      "[0.72413793]\n",
      "[0.85057471]\n",
      "[0.29885057]\n",
      "[0.74712644]\n",
      "[0.81609195]\n",
      "[0.28735632]\n",
      "[0.65517241]\n",
      "[0.29885057]\n",
      "[0.06896552]\n",
      "[1.]\n",
      "[0.96551724]\n",
      "[0.72413793]\n",
      "[0.5862069]\n",
      "[0.05747126]\n",
      "[0.01149425]\n",
      "[0.97701149]\n",
      "[0.40229885]\n",
      "[0.48275862]\n",
      "[0.02298851]\n",
      "[0.47126437]\n",
      "[0.26436782]\n",
      "[0.20689655]\n",
      "[0.01149425]\n",
      "[0.22988506]\n",
      "[0.70114943]\n",
      "[0.1954023]\n",
      "[0.68965517]\n",
      "[0.51724138]\n",
      "[0.42528736]\n",
      "[0.86206897]\n",
      "[0.40229885]\n",
      "[0.97701149]\n",
      "[0.50574713]\n",
      "[0.2183908]\n",
      "[0.94252874]\n",
      "[0.13793103]\n",
      "[0.70114943]\n",
      "[0.70114943]\n",
      "[0.10344828]\n",
      "[0.96551724]\n",
      "[0.33333333]\n",
      "[0.12643678]\n",
      "[0.01149425]\n",
      "[0.10344828]\n",
      "[0.40229885]\n",
      "[0.13793103]\n",
      "[0.87356322]\n",
      "[0.1954023]\n",
      "[0.18390805]\n",
      "[0.68965517]\n",
      "[0.64367816]\n",
      "[0.67816092]\n",
      "[0.4137931]\n",
      "[0.67816092]\n",
      "[0.66666667]\n",
      "[0.31034483]\n",
      "[0.96551724]\n",
      "[0.91954023]\n",
      "[0.89655172]\n",
      "[0.04597701]\n",
      "[0.79310345]\n",
      "[0.85057471]\n",
      "[0.85057471]\n",
      "[0.72413793]\n",
      "[0.93103448]\n",
      "[0.06896552]\n",
      "[0.14942529]\n",
      "[0.10344828]\n",
      "[0.28735632]\n",
      "[0.06896552]\n",
      "[0.85057471]\n",
      "[0.79310345]\n",
      "[0.94252874]\n",
      "[0.31034483]\n",
      "[0.89655172]\n",
      "[0.45977011]\n",
      "[0.03448276]\n",
      "[0.4137931]\n",
      "[0.28735632]\n",
      "[0.81609195]\n",
      "[0.26436782]\n",
      "[0.72413793]\n",
      "[0.57471264]\n",
      "[0.17241379]\n",
      "[0.2183908]\n",
      "[0.83908046]\n",
      "[0.34482759]\n",
      "[0.40229885]\n",
      "[0.26436782]\n",
      "[0.66666667]\n",
      "[0.82758621]\n",
      "[0.79310345]\n",
      "[0.33333333]\n",
      "[0.91954023]\n",
      "[0.08045977]\n",
      "[0.90804598]\n",
      "[0.08045977]\n",
      "[0.8045977]\n",
      "[0.81609195]\n",
      "[0.93103448]\n",
      "[0.87356322]\n",
      "[0.7816092]\n",
      "[0.47126437]\n",
      "[0.85057471]\n",
      "[0.28735632]\n",
      "[0.01149425]\n",
      "[0.73563218]\n",
      "[0.96551724]\n",
      "[1.]\n",
      "[0.87356322]\n",
      "[0.93103448]\n",
      "[0.83908046]\n",
      "[0.96551724]\n",
      "[0.62068966]\n",
      "[0.95402299]\n",
      "[0.11494253]\n",
      "[1.]\n",
      "[0.96551724]\n",
      "[0.47126437]\n",
      "[0.47126437]\n",
      "[0.11494253]\n",
      "[0.68965517]\n",
      "[0.95402299]\n",
      "[0.59770115]\n",
      "[0.64367816]\n",
      "[0.42528736]\n",
      "[0.93103448]\n",
      "[0.54022989]\n",
      "[0.65517241]\n",
      "[0.89655172]\n",
      "[0.42528736]\n",
      "[0.91954023]\n",
      "[0.62068966]\n",
      "[0.66666667]\n",
      "[0.85057471]\n",
      "[0.56321839]\n",
      "[0.95402299]\n",
      "[0.37931034]\n",
      "[0.65517241]\n",
      "[0.68965517]\n",
      "[0.96551724]\n",
      "[0.14942529]\n",
      "[0.42528736]\n",
      "[0.82758621]\n",
      "[0.31034483]\n",
      "[0.06896552]\n",
      "[0.95402299]\n",
      "[0.36781609]\n",
      "[0.89655172]\n",
      "[0.48275862]\n",
      "[0.33333333]\n",
      "[0.87356322]\n",
      "[0.35632184]\n",
      "[0.8045977]\n",
      "[0.10344828]\n",
      "[0.85057471]\n",
      "[0.47126437]\n",
      "[0.57471264]\n"
     ]
    }
   ],
   "source": [
    "for i in scaled_train_samples:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b4b185d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 1)\n"
     ]
    }
   ],
   "source": [
    "print(scaled_train_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1a88f9",
   "metadata": {},
   "source": [
    "At this point, we've generated some sample raw data, put it into the numpy format that our model will require, and rescaled it to a scale ranging from 0 to 1.\n",
    "\n",
    "In an upcoming episode, we'll use this data to train a neural network and see what kind of results we can get. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80264d7",
   "metadata": {},
   "source": [
    "## Create an artificial neural network with TensorFlow's Keras API\n",
    "\n",
    "In this episode, we'll demonstrate how to create a simple artificial neural network using a **Sequential model** from the Keras API integrated within TensorFlow.\n",
    "\n",
    "https://deeplizard.com/images/png/deep%20neural%20network%20with%204%20layers.png\n",
    "\n",
    "In the last episode, we generated some data from an imagined clinical trial, and now we'll build a simple model for which we can train on this data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0283b1",
   "metadata": {},
   "source": [
    "## Code Setup\n",
    "\n",
    "First, we need to import all the libraries we'll be making use of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b132700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b4af1",
   "metadata": {},
   "source": [
    "We'll use all of these modules, except for the last two, to **build our neural network**. Note that we'll make use of the last two modules in the next episode when we **train** the model.\n",
    "\n",
    "A GPU is not required to follow this course, but if you are using one, you'll need to first follow the GPU setup we covered in a previous episode. We can then check to be sure that TensorFlow is able to identify the GPU using the code below. It's also useful to enable memory growth on the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d790f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(physical_devices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a208acd8",
   "metadata": {},
   "source": [
    "##  Build a Sequential Model\n",
    "\n",
    "Let's now create our model. We first create a variable named model and define it as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6275178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=16, input_shape=(1,), activation='relu'),\n",
    "    Dense(units=32, activation='relu'),\n",
    "    Dense(units=2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e1dc2",
   "metadata": {},
   "source": [
    "***model*** is an instance of a Sequential object. A tf.keras.Sequential model is a linear stack of layers. It accepts a list, and each element in the list should be a layer.\n",
    "\n",
    "As you can see, we have passed a list of layers to the Sequential constructor. Let's go through each of the layers in this list now. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8818e",
   "metadata": {},
   "source": [
    "### First Hidden Layer\n",
    "\n",
    "Our first layer is a **Dense** layer. This type of layer is our standard **fully-connected or densely-connected** neural network layer. The first required parameter that the Dense layer expects is the number of neurons or units the layer has, and we're arbitrarily setting this to 16.\n",
    "\n",
    "Additionally, the model needs to know the shape of the input data. For this reason, we specify the shape of the input data in the first hidden layer in the model (and only this layer). The parameter called input_shape is how we specify this.\n",
    "\n",
    "As discussed, we'll be training our network on the data that we generated and processed in the previous episode, and recall, this data is one-dimensional. The input_shape parameter expects a tuple of integers that matches the shape of the input data, so we correspondingly specify (1,) as the input_shape of our one-dimensional data.\n",
    "\n",
    "You can think of the way we specify the input_shape here as acting as an implicit input layer. The input layer of a neural network is the underlying raw data itself, therefore we don't create an explicit input layer. This first Dense layer that we're working with now is actually the first hidden layer.\n",
    "\n",
    "Lastly, an optional parameter that we'll set for the Dense layer is the activation function to use after this layer. We'll use the popular choice of **relu**. Note, if you don't explicitly set an activation function, then Keras will use the linear activation function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf72410f",
   "metadata": {},
   "source": [
    "### Second Hidden Layer\n",
    "\n",
    "Our next layer will also be a Dense layer, and this one will have 32 nodes. The choice of how many neurons this node has is also arbitrary, as the idea is to create a simple model, and then test and experiment with it. If we notice that it is insufficient, then at that time, we can troubleshoot the issue and begin experimenting with changing parameters, like number of layers, nodes, etc.\n",
    "\n",
    "This Dense layer will also use relu as its activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54410d49",
   "metadata": {},
   "source": [
    "### Output layer\n",
    "\n",
    "Lastly, we specify the output layer. This layer is also a Dense layer, and it will have **2 neurons**. This is because we have two possible outputs: either a patient experienced side effects, or the patient did not experience side effects.\n",
    "\n",
    "This time, the activation function we'll use is softmax, which will give us a probability distribution among the possible outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5587f781",
   "metadata": {},
   "source": [
    "Note that we can call summary() on our model to get a quick visualization of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc1fda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 16)                32        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 642\n",
      "Trainable params: 642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c69130b",
   "metadata": {},
   "source": [
    "Now we've created our very first model using the intuitive tf.keras.Sequential model type. In the next episode we'll train this model on the data we created last time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7268eb5",
   "metadata": {},
   "source": [
    "## Train an Artificial Neural Network with TensorFlow's Keras API\n",
    "\n",
    "In this episode, we'll demonstrate how to train an artificial neural network using the Keras API integrated within TensorFlow.\n",
    "\n",
    "In the previous episode, we went through the steps to build a simple network, and now we'll focus on training it using data we generated in an even earlier episode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee974ce",
   "metadata": {},
   "source": [
    "##  Compiling the model\n",
    "\n",
    "The first thing we need to do to get the model ready for training is call the **compile()** function on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38d1852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74822d4",
   "metadata": {},
   "source": [
    "This function configures the model for training and expects a number of parameters. First, we specify the **optimizer Adam**. Adam accepts an optional parameter **learning_rate**, which we'll set to 0.0001. Adam optimization is a **stochastic gradient descent (SGD) method**.\n",
    "\n",
    "The next parameter we specify is **loss**. We'll be using **sparse_categorical_crossentropy**, given that our labels are in integer format.\n",
    "\n",
    "Note that when we have only two classes, we could instead configure our output layer to have only one output, rather than two, and use **binary_crossentropy as our loss**, rather than categorical_crossentropy. Both options work equally well and achieve the exact same result.\n",
    "\n",
    "With **binary_crossentropy**, however, the last layer would need to use **sigmoid**, rather than softmax, as its activation function.\n",
    "\n",
    "Moving on, the last parameter we specify in **compile()** is metrics. This parameter expects a list of metrics that we'd like to be evaluated by the model during training and testing. We'll set this to a list that contains the string **âaccuracy'**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ece981c",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    " Now that the model is compiled, we can train it using the fit() function.\n",
    " \n",
    "The first item that we pass in to the fit() function is the training set **x**. Recall from a previous episode, we created the training set and gave it the name scaled_train_samples.\n",
    "\n",
    "The next parameter that we set is the labels for the training set **y**, which we previously gave the name train_labels. We then specify the **batch_size**.\n",
    "\n",
    "Next, we specify how many **epochs** we want to run. We set this to 30. Note that an epoch is a single pass of all the data to the network.\n",
    "\n",
    "Lastly, we specify **verbose=2**. This just specifies how much output to the console we want to see during each epoch of training. The verbosity levels range from 0 to 2, so we're getting the most verbose output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "604df616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae722e8",
   "metadata": {},
   "source": [
    "We can see corresponding output for each of the 30 epochs. Judging by the loss and accuracy, we can see that both metrics steadily improve over time with accuracy reaching almost 94% and loss steadily decreasing until we reach 0.25.\n",
    "\n",
    "Note that although this is a very simple model trained on simple data, without much effort, we were able to reach pretty good results in a relatively quick manner of time. In subsequent episodes, we'll demo more complex models as well as more complex data, but hopefully you've become encouraged by how easily we were able to get started with tf.keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8245d26",
   "metadata": {},
   "source": [
    "##  Build a validation set with TensorFlow's Keras API\n",
    "\n",
    "In this episode, we'll demonstrate how to use TensorFlow's Keras API to create a validation set on-the-fly during training.\n",
    "\n",
    "We'll continue working with the same model we built and trained in the previous episode, but first, let's discuss what exactly a validation set is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a734b09",
   "metadata": {},
   "source": [
    "## What is a validation set?\n",
    "\n",
    "Recall that we previously built a training set on which we trained our model. With each epoch that our model is trained, the model will continue to learn the features and characteristics of the data in this training set.\n",
    "\n",
    "The hope is that later we can take this model, apply it to new data, and have the model accurately predict on data that it hasn't seen before based solely on what it learned from the training set.\n",
    "\n",
    "Now, let's discuss where the addition of a validation set comes into play.\n",
    "\n",
    "Before training begins, we can choose to remove a portion of the training set and place it in a validation set. Then, during training, the model will train only on the training set, and it will validate by evaluating the data in the validation set.\n",
    "\n",
    "Essentially, the model is learning the features of the data in the training set, taking what it's learned from this data, and then predicting on the validation set. During each epoch, we will see not only the loss and accuracy results for the training set, but also for the validation set.\n",
    "\n",
    "This allows us to see how well the model is generalizing on data it wasn't trained on because, recall, the validation data should not be part of the training data.\n",
    "\n",
    "This also helps us see whether or not the model is **overfitting**. Overfitting occurs when the model only learns the specifics of the training data and is unable to generalize well on data that it wasn't trained on. Now let's discuss how we can create a validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de425a6",
   "metadata": {},
   "source": [
    "## Creating A Validation Set\n",
    "\n",
    "There are two ways to create a validation set to use with a **tf.keras.Sequential** model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19838f16",
   "metadata": {},
   "source": [
    "###  Manually create validation set\n",
    "\n",
    "The first way is to create a data structure to hold a validation set, and place data directly in that structure in the same nature we did for the training set.\n",
    "\n",
    "This data structure should be a tuple **valid_set = (x_val, y_val)** of Numpy arrays or tensors, where x_val is a numpy array or tensor containing validation samples, and y_val is a numpy array or tensor containing validation labels.\n",
    "\n",
    "When we call **model.fit()**, we would pass in the validation set in addition to the training set. We pass the validation set by specifying the **validation_data** parameter.\n",
    "\n",
    "model.fit(\n",
    "      x=scaled_train_samples\n",
    "    , y=train_labels\n",
    "    , validation_data=valid_set\n",
    "    , batch_size=10\n",
    "    , epochs=30\n",
    "    , verbose=2\n",
    ")\n",
    "\n",
    "When the model trains, it would continue to train only on the training set, but additionally, it would also be evaluating the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ab8f1",
   "metadata": {},
   "source": [
    "###  Create Validation Set With Keras\n",
    "\n",
    "There is another way to create a validation set, and it saves a step!\n",
    "\n",
    "If we don't already have a specified validation set created, then when we call **model.fit()**, we can set a value for the **validation_split** parameter. It expects a fractional number between 0 and 1. Suppose that we set this parameter to 0.1.\n",
    "\n",
    "model.fit(\n",
    "      x=scaled_train_samples\n",
    "    , y=train_labels\n",
    "    , validation_split=0.1\n",
    "    , batch_size=10\n",
    "    , epochs=30\n",
    "    , verbose=2\n",
    ")\n",
    "\n",
    "With this parameter specified, Keras will split apart a fraction (10% in this example) of the training data to be used as validation data. The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch.\n",
    "\n",
    "Note that the **fit()** function shuffles the data before each epoch by default. When specifying the **validation_split** parameter, however, the validation data is selected from the last samples in the x and y data before shuffling.\n",
    "\n",
    "**Therefore, in the case we're using validation_split in this way to create our validation data, we need to be sure that our data has been shuffled ahead of time, like we previously did in an earlier episode**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06ef10",
   "metadata": {},
   "source": [
    "##  Interpret Validation Metrics\n",
    "\n",
    "Now, regardless of which method we use to create validation data, when we call **model.fit()**, then in addition to loss and accuracy being displayed for each epoch as we saw last time, we will now also see **val_loss** and **val_acc** to track the loss and accuracy on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de58256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "189/189 - 0s - loss: 0.7027 - accuracy: 0.5254 - val_loss: 0.6823 - val_accuracy: 0.6714\n",
      "Epoch 2/30\n",
      "189/189 - 0s - loss: 0.6670 - accuracy: 0.6788 - val_loss: 0.6459 - val_accuracy: 0.7095\n",
      "Epoch 3/30\n",
      "189/189 - 0s - loss: 0.6335 - accuracy: 0.7122 - val_loss: 0.6094 - val_accuracy: 0.7190\n",
      "Epoch 4/30\n",
      "189/189 - 0s - loss: 0.5990 - accuracy: 0.7550 - val_loss: 0.5744 - val_accuracy: 0.7619\n",
      "Epoch 5/30\n",
      "189/189 - 0s - loss: 0.5661 - accuracy: 0.7899 - val_loss: 0.5409 - val_accuracy: 0.7714\n",
      "Epoch 6/30\n",
      "189/189 - 0s - loss: 0.5338 - accuracy: 0.8138 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 7/30\n",
      "189/189 - 0s - loss: 0.5020 - accuracy: 0.8302 - val_loss: 0.4769 - val_accuracy: 0.8429\n",
      "Epoch 8/30\n",
      "189/189 - 0s - loss: 0.4709 - accuracy: 0.8455 - val_loss: 0.4473 - val_accuracy: 0.8476\n",
      "Epoch 9/30\n",
      "189/189 - 0s - loss: 0.4420 - accuracy: 0.8587 - val_loss: 0.4204 - val_accuracy: 0.8857\n",
      "Epoch 10/30\n",
      "189/189 - 0s - loss: 0.4161 - accuracy: 0.8778 - val_loss: 0.3965 - val_accuracy: 0.8952\n",
      "Epoch 11/30\n",
      "189/189 - 0s - loss: 0.3926 - accuracy: 0.8868 - val_loss: 0.3762 - val_accuracy: 0.9095\n",
      "Epoch 12/30\n",
      "189/189 - 0s - loss: 0.3726 - accuracy: 0.9037 - val_loss: 0.3576 - val_accuracy: 0.9095\n",
      "Epoch 13/30\n",
      "189/189 - 0s - loss: 0.3550 - accuracy: 0.9069 - val_loss: 0.3422 - val_accuracy: 0.9095\n",
      "Epoch 14/30\n",
      "189/189 - 0s - loss: 0.3400 - accuracy: 0.9106 - val_loss: 0.3298 - val_accuracy: 0.9190\n",
      "Epoch 15/30\n",
      "189/189 - 0s - loss: 0.3275 - accuracy: 0.9143 - val_loss: 0.3193 - val_accuracy: 0.9190\n",
      "Epoch 16/30\n",
      "189/189 - 0s - loss: 0.3168 - accuracy: 0.9175 - val_loss: 0.3109 - val_accuracy: 0.9286\n",
      "Epoch 17/30\n",
      "189/189 - 0s - loss: 0.3081 - accuracy: 0.9233 - val_loss: 0.3033 - val_accuracy: 0.9286\n",
      "Epoch 18/30\n",
      "189/189 - 0s - loss: 0.3003 - accuracy: 0.9291 - val_loss: 0.2970 - val_accuracy: 0.9286\n",
      "Epoch 19/30\n",
      "189/189 - 0s - loss: 0.2941 - accuracy: 0.9254 - val_loss: 0.2921 - val_accuracy: 0.9286\n",
      "Epoch 20/30\n",
      "189/189 - 0s - loss: 0.2888 - accuracy: 0.9286 - val_loss: 0.2880 - val_accuracy: 0.9286\n",
      "Epoch 21/30\n",
      "189/189 - 0s - loss: 0.2842 - accuracy: 0.9296 - val_loss: 0.2848 - val_accuracy: 0.9333\n",
      "Epoch 22/30\n",
      "189/189 - 0s - loss: 0.2802 - accuracy: 0.9291 - val_loss: 0.2817 - val_accuracy: 0.9333\n",
      "Epoch 23/30\n",
      "189/189 - 0s - loss: 0.2771 - accuracy: 0.9317 - val_loss: 0.2795 - val_accuracy: 0.9333\n",
      "Epoch 24/30\n",
      "189/189 - 0s - loss: 0.2741 - accuracy: 0.9302 - val_loss: 0.2778 - val_accuracy: 0.9333\n",
      "Epoch 25/30\n",
      "189/189 - 0s - loss: 0.2716 - accuracy: 0.9354 - val_loss: 0.2759 - val_accuracy: 0.9333\n",
      "Epoch 26/30\n",
      "189/189 - 0s - loss: 0.2695 - accuracy: 0.9354 - val_loss: 0.2745 - val_accuracy: 0.9333\n",
      "Epoch 27/30\n",
      "189/189 - 0s - loss: 0.2676 - accuracy: 0.9354 - val_loss: 0.2730 - val_accuracy: 0.9333\n",
      "Epoch 28/30\n",
      "189/189 - 0s - loss: 0.2657 - accuracy: 0.9354 - val_loss: 0.2723 - val_accuracy: 0.9333\n",
      "Epoch 29/30\n",
      "189/189 - 0s - loss: 0.2642 - accuracy: 0.9360 - val_loss: 0.2715 - val_accuracy: 0.9333\n",
      "Epoch 30/30\n",
      "189/189 - 0s - loss: 0.2628 - accuracy: 0.9397 - val_loss: 0.2703 - val_accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20656343a00>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_train_samples,\n",
    "          y=train_labels,\n",
    "          validation_split=0.1,\n",
    "          batch_size=10,\n",
    "          epochs=30,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e792666a",
   "metadata": {},
   "source": [
    "We can now see not only how well our model is learning the features of the training data, but also how well the model is generalizing to new, unseen data from the validation set. Next, we'll see how to use our model for inference. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
